[00:00:00.000] Ça y est, maintenant, on a trouvé le secret de l'intelligence.
[00:00:02.480] D'ici 10 ans, on aura des machines aussi intelligentes que les humains.
[00:00:05.000] Yann LeCun, ou de l'autre côté de l'Atlantique, c'est plutôt Yann LeCun.
[00:00:09.160] Découvrir le mystère de l'intelligence et construire des machines intelligentes, je pense que c'est la seule manière de valider si des idées abstraites fonctionnent.
[00:00:16.160] En fait, le LLM s'est plié.
[00:00:17.360] Maintenant, c'est parti dans une équipe produit.
[00:00:19.360] C'est plus de la recherche.
[00:00:20.360] Un peu, oui.
[00:00:20.959] J'étais pas prêt à cette...
[00:00:22.280] Elon M.
[00:00:24.840] Elon M, oui, il avait été mercredé, mais ça a pas marché.
[00:00:27.600] Du coup, ça me fait penser à Apple et son casque, là.
[00:00:30.360] Tu peux pas le chauffer, Yann LeCun.
[00:00:32.080] Apple essaie de rattraper leur retard et ils sortent un truc à bord qui est moins bon et qui est 7 fois plus cher.
[00:00:38.520] Donc, non, je suis pas impressionné.
[00:00:40.160] Bientôt, ça sera dans les lunettes intelligentes et on aura les sous-titres qui s'affichent si on parle à quelqu'un dans une langue étrangère.
[00:00:46.240] Dès qu'une prédiction est violée, on est obligé d'y prêter attention parce que ça veut dire que notre modèle du monde était faux.
[00:00:50.799] C'est des réseaux cognitifs, c'est un peu une invention qui date de 35 ans et qui détecte les objets qu'on a besoin de détecter.
[00:00:56.919] Je ne crois pas à l'application du calcul quantique à l'IA et en fait, je suis très sceptique sur le calcul quantique.
[00:01:02.880] Tu pourrais envisager qu'un LLM comme ça invente une langue et tu lui proposes une langue inventée peut-être par un autre LLM et qu'il comprenne.
[00:01:11.000] Oui, absolument.
[00:01:11.879] Donc, simplement en observant le monde pendant quelques mois ou même quelques centaines d'heures, on a plus d'informations, en fait, plus de données que la totalité du texte disponible sur Internet.
[00:01:21.599] Il y a des choses qui te font peur dans l'IA.
[00:01:27.919] Nous y voilà, cet épisode tant attendu.
[00:01:31.239] C'est marrant parce que tu n'as peut-être pas des groupies très souvent, mais je suis presque un groupie d'Yann Lequin.
[00:01:37.559] Autant, j'ai des gens qui ont l'habitude d'avoir des groupies ici, des Bob Sinclar, des artistes dédigés, voilà.
[00:01:44.839] Mais j'ai écouté beaucoup de tes épisodes, les trois épisodes, je crois, chez Lex Friedman.
[00:01:51.320] Le dernier était dense, pointu.
[00:01:56.000] En plus, je ne connais pas Lex Friedman personnellement, mais il est très sharp, donc vous allez assez loin.
[00:02:04.800] Et moi, ce que je te propose aujourd'hui, Yann, c'est d'aller, au moins de reposer les bases.
[00:02:09.399] Si on peut aller loin, je suis très content, mais déjà aussi de reposer les bases de l'IA, des LLM.
[00:02:17.360] Aussi, toi, ce que tu penses, ce qui m'intéresse, c'est que j'ai eu sur Génération du Turcelfe des épisodes très sympas autour de l'IA, mais il y en a qui sont plus flamboyants ou qui vont faire fantasmer aussi.
[00:02:34.440] J'ai reçu des gens comme Laurent Alexandre, que tu connais peut-être de près, de loin, avec qui je m'éclate et que j'aime beaucoup, d'ailleurs, avec qui on s'écharpe aussi dans chaque épisode.
[00:02:44.960] Mais voilà, et j'aimerais comprendre un peu pour toi, de l'intérieur de chez Fer, notamment, où est-ce que vous en êtes ?
[00:02:56.000] Qu'est-ce que tu vois ? Qu'est-ce que tu comprends ?
[00:02:58.279] Qu'est-ce que tu vois à travers tes Ray-Bans méta ?
[00:03:01.639] Qui me filment en ce moment, non, qui ne me filment pas, justement.
[00:03:06.119] Et puis, j'aimerais aussi comprendre, et peut-être pour les plus jeunes qui nous écoutent, comment on peut, en partant de France, finir un job qui est quand même l'un des plus hauts de l'IA dans le monde.
[00:03:22.199] Tu vois, il y a Sam Altman, il y a Yann Lequin, quoi, tu vois.
[00:03:24.639] Donc voilà, peut-être se dire que c'est possible et comprendre comment on y arrive, en tout cas, comment tu y es arrivé, comment cette trajectoire des années 80, tu voyais déjà, semble-t-il, pas mal de choses.
[00:03:39.279] En tout cas, tu commençais à tripatouiller pas mal de choses.
[00:03:42.839] Voilà, ça te va comme programme ?
[00:03:43.919] Ça va très bien.
[00:03:44.720] Je te propose avant tout ça, si tu veux bien, de te présenter, Yann.
[00:03:48.000] D'accord.
[00:03:51.119] Donc, Yann Lequin, ou de l'autre côté de l'Atlantique, c'est plutôt Yann Lecun.
[00:03:58.559] Et puis, ça ne s'écrit pas pareil parce que mon nom s'écrit en deux mots, mais aux Etats-Unis, les gens ne comprennent pas que le, ce n'est pas mon middle name, donc j'ai à coller les deux.
[00:04:09.839] Je suis Chief AI Scientist, donc scientifique en chef à Meta.
[00:04:14.479] J'y suis depuis un peu plus de dix ans et je suis aussi professeur à New York University, qu'on appelait NYU, donc une des grandes universités privées de New York depuis une vingtaine d'années.
[00:04:27.359] Et puis, j'avais commencé avant ça, ma carrière dans l'industrie, dans les laboratoires de recherche de la compagnie AT&T, qui était une grosse compagnie de recherche, la compagnie AT&T, une grosse compagnie de téléphone, qui avait un labo mythique qui s'appelle Bell Labs, Bell Laboratories, dans lequel une grande partie de la technologie du monde moderne a été inventée, en particulier les transistors.
[00:04:51.720] Voilà.
[00:04:52.559] Intéressant.
[00:04:53.959] Je ne savais pas, tu vois, que NYU était privée, en l'occurrence avec un nom comme NYU, tu aurais pu te dire que c'était public, mais alors, les universités publiques, Princeton ou...
[00:05:04.559] Princeton est privée, Columbia, qui est aussi à New York, est aussi privée.
[00:05:08.880] Et il y a une université qui s'appelle City University of New York, CUNY, qui est publique, qui appartient à la ville.
[00:05:15.320] OK.
[00:05:16.320] Et puis, il y a d'autres universités d'État qui appartiennent à l'État de New York, l'État du New Jersey, Rutgers University est publique dans le New Jersey.
[00:05:23.399] OK.
[00:05:24.640] Intéressant.
[00:05:27.239] Écoute, je trouve qu'aujourd'hui, en 2024, quand on échange, alors, le monde a pris un 33 tonnes dans la gueule il y a 18 mois, en gros, avec la sortie de GPT-3.
[00:05:44.239] J'ai l'impression que toi, tu n'as même pas pris une piche nette et que ça ne t'a pas complètement bouleversé.
[00:05:52.239] Mais c'était un peu la vraie découverte pour l'humanité, quand même, de la puissance potentielle d'un LLM.
[00:05:59.679] Et toi, j'ai l'impression qu'aujourd'hui, tu dis oui, c'est bien, mais ce n'est pas non plus...
[00:06:07.200] Tu vois, on est quand même très loin de tout ce qui est annoncé par beaucoup.
[00:06:10.959] Est-ce que tu peux m'expliquer un peu, me réexpliquer comment fonctionne un LLM et peut-être pourquoi c'est limité ?
[00:06:17.000] D'accord. Alors, la première chose, c'est l'apparition de LLM, disons, dans le public, qui a été révélée un petit peu avec ChatGPT à la fin 2022, n'a pas été vraiment du tout une révolution pour des gens qui sont dans la recherche de l'IA, parce que ce genre de technique, en fait, existe depuis assez longtemps et puis on connaît leurs possibilités.
[00:06:41.279] Ce qui a choqué un peu tout le monde à la sortie de ChatGPT, c'est l'engouement du public pour ce genre de système.
[00:06:47.079] Il y a une histoire assez amusante, c'est que trois semaines avant l'apparition publique de ChatGPT chez Meta, on avait sorti un LLM qui s'appelait Galactica et qui avait été entraîné de manière très spécifique pour aider les chercheurs à écrire des articles scientifiques.
[00:07:04.079] Donc, ce système avait été entraîné sur la totalité de la littérature scientifique disponible publiquement et c'était fait pour aider les gens, surtout qu'il y en a plein dont l'anglais n'est pas la langue natale, donc c'est un peu compliqué d'écrire en anglais.
[00:07:17.720] Donc, ça allait être très utile, on était très fiers de nous.
[00:07:20.239] Et quand on a mis la démo, rendu la démo disponible, elle a été assassinée, arrosée de vitrioles par Twitter.
[00:07:31.760] La sphère de Twitter en particulier, ou disons sur les réseaux sociaux, par des gens bien ou mal intentionnés, mais y compris des scientifiques eux-mêmes disant ça va détruire le système de publication scientifique.
[00:07:43.160] Maintenant, n'importe quel imbécile peut écrire un article qui apparaît être authentique, etc.
[00:07:50.839] Et donc, c'est un gros danger, ça va détruire la société.
[00:07:54.679] Donc, au bout de trois jours, les chercheurs de fer qui avaient construit le système ont éteint la démo parce qu'ils se sont dit qu'ils n'endormaient pas la nuit.
[00:08:05.200] Et donc, le résultat de cette négativité a été fait qu'un outil qui aurait pu être très, très utile pour la communauté scientifique, en fait, a disparu.
[00:08:16.119] Trois semaines plus tard, ChetJPT est sorti, et là, c'est la deuxième descente du Messie du paradis.
[00:08:25.119] C'était vraiment un choc pour nous, en fait, le fait que les gens, en fait, s'intéressent tant à ces technologies qui, par ailleurs, avaient été vraiment très fortement critiquées.
[00:08:34.599] Et Galactica n'était pas le premier système qu'on avait sorti comme ça.
[00:08:37.719] Il y en a eu plusieurs les années précédentes.
[00:08:39.479] Il y avait eu sur Twitter aussi cet effet, chez Microsoft, où il y avait eu un...
[00:08:43.239] Alors ça, c'est beaucoup plus tôt ce détail, un système qui avait été déployé en Chine pour Conversation, et quand ils l'ont déployé aux Etats-Unis et dans le reste, le truc a été trollé pour 24 heures et transformé en néo-nazi.
[00:09:00.719] Puisque les gens, en fait, avaient compris que si on tapait des choses, le système, en fait, utilisait ces phrases et les réutilisait dans les autres dialogues.
[00:09:10.760] Et donc, il s'est fait troller immédiatement.
[00:09:14.039] Ça a été une belle leçon pour Microsoft.
[00:09:17.159] Et puis, les différences culturelles entre la Chine et le reste du monde.
[00:09:22.320] Non, là, mais ce n'était pas un LLM à l'époque.
[00:09:25.320] Mais il y a eu pas mal de LLM.
[00:09:26.520] En fait, la révolution un petit peu technologique, ça a été le Deep Learning, déjà, qui est avec nous depuis une quinzaine d'années.
[00:09:34.760] Ensuite, tu peux réexpliquer en une phrase ou deux à chaque fois, le Deep Learning et le LLM, si tu veux bien.
[00:09:42.599] Alors, Deep Learning, c'est un ensemble de techniques pour entraîner les machines au lieu d'avoir les programmées directement.
[00:09:49.280] C'est-à-dire qu'on peut les entraîner à accomplir une tâche.
[00:09:53.080] Et très souvent, ça utilise ce qu'on appelle l'apprentissage supervisé.
[00:09:55.479] Donc, par exemple, on peut entraîner une machine à reconnaître des objets dans les images.
[00:10:01.000] On lui montre une image d'un chien, d'un chat, d'une table, d'une chaise.
[00:10:05.159] Donc, par exemple, disons une table.
[00:10:07.159] On attend la réponse du système.
[00:10:08.799] Si le système dit table, on ne fait rien.
[00:10:10.200] Et si le système dit chaise ou chien ou chat, on lui dit non.
[00:10:14.359] La réponse, c'est table.
[00:10:16.080] Et le système change ses paramètres internes.
[00:10:18.559] C'est des coefficients, en fait, dans des formules mathématiques très simples qui font des additions, des multiplications, de manière à ce que la sortie se rapproche de celle qu'on veut.
[00:10:27.679] Donc, ça, ça marche très bien pour des choses comme la reconnaissance d'images, la traduction, la reconnaissance de paroles, des choses comme ça.
[00:10:36.239] Ça, c'est le supervisé.
[00:10:37.359] C'est le supervisé.
[00:10:38.200] Alors, il y a une autre méthode d'apprentissage dans laquelle les gens avaient mis beaucoup d'espoir il y a une dizaine d'années, sur laquelle DeepMind, qui appartient à Google maintenant, s'était entièrement fondé, qui s'appelle l'apprentissage par renforcement.
[00:10:49.640] Et alors là, on ne dit pas à la machine quelle est la réponse correcte.
[00:10:52.760] On dit à la machine si la réponse qu'elle a produite est bonne ou pas bonne.
[00:10:57.799] Ou il donne un espèce de score.
[00:10:59.840] Et ça, c'est très pratique si on veut entraîner une machine, par exemple, à jouer aux échecs, au poker, au go, etc.
[00:11:04.880] Parce qu'à la fin, automatiquement, on peut déterminer si la machine a gagné la partie ou perdu, donc savoir si la manière dont elle a joué était bonne ou pas.
[00:11:17.000] Et en jouant des millions de parties, le système peut se raffiner et finalement être super humain.
[00:11:21.479] De loin, j'allais dire de loin, on a l'impression qu'il y en a une où on lui apprend à réfléchir, mais ça ne doit pas être exactement le cas.
[00:11:29.159] Et dans l'autre, on lui dit vrai, faux, mais tout bête.
[00:11:32.880] Mais ce n'est pas le cas.
[00:11:34.280] Il y en a un où on lui donne la réponse et l'autre, on lui dit simplement si c'est vrai ou faux.
[00:11:38.599] S'il y a beaucoup de réponses possibles, en fait, c'est très, très inefficace parce que le système doit essayer.
[00:11:43.599] Alors, c'est ça la bonne réponse ? Ou alors c'est ça ? Ou alors c'est ça ?
[00:11:45.960] Et à chaque fois...
[00:11:46.719] C'est une chaise, c'est une pomme, c'est un avion ?
[00:11:49.280] Donc, s'il y a 10 000 possibilités, ça risque de prendre du temps.
[00:11:52.280] Et dans le cas d'un jeu d'échecs, etc., ce n'est pas grave.
[00:11:57.159] On peut faire en sorte que le système joue des millions, des millions de parties.
[00:12:01.119] Donc, ça finit par marcher.
[00:12:02.280] Mais il y avait beaucoup d'espoir que ce type d'apprentissage, en fait, qui se rapproche un petit peu de l'espèce de conditionnement et la Pavlov, en fait, serait la base de l'apprentissage chez les humains et les animaux.
[00:12:14.239] Il s'avère que, en fait, non, pas du tout.
[00:12:15.479] C'est tellement inefficace qu'il n'y a absolument aucune chance qu'on puisse utiliser ce genre de méthode pour entraîner des systèmes, par exemple, à conduire une voiture ou quoi que ce soit.
[00:12:25.520] Donc, cet espoir a complètement disparu.
[00:12:29.039] DeepMind s'est complètement ailleurs orienté, a complètement abandonné, en fait, plus ou moins, cette approche.
[00:12:34.440] Donc, on a surprévisé.
[00:12:35.919] Le deuxième, tu m'as dit, c'est renforcement.
[00:12:38.359] Et le troisième, c'est auto-supervisé ou non-supervisé.
[00:12:41.239] Et alors là, c'est ce qu'utilisent les LLM.
[00:12:43.679] C'est donc une méthode dont je me suis fait un petit peu le défenseur ou l'avocat depuis près d'une dizaine d'années et qui est une technique dans laquelle on n'entraîne pas le système à faire une tâche particulière, mais on l'entraîne à représenter, comprendre la structure de l'entrée.
[00:13:04.599] Alors, dans le cas du texte, dans le cas des LLM, par exemple, on prend un bout de texte, une séquence de quelques centaines ou quelques milliers de mots et on le corrompt.
[00:13:17.119] On masque certains mots, on les remplace par des marqueurs blancs ou on substitue certains mots, etc.
[00:13:25.280] Donc, on rend le texte ou l'entrée, ça peut marcher avec une image aussi, corrompue.
[00:13:33.599] Et ensuite, on entraîne un grand réseau de neurones, donc un système de deep learning, à prédire les mots qui manquent ou les mots qui étaient faux, c'est-à-dire à reconstruire l'entrée complète à partir d'une entrée incomplète.
[00:13:46.119] Donc, c'est basé sur une vieille idée qui s'appelle les auto-encodeurs de débruitage.
[00:13:52.000] Ça date des années 80, c'est vraiment vieux, mais l'application à la compréhension de texte, en fait, est plus récente.
[00:13:59.159] Ça date des années 2016 ou 2015.
[00:14:02.760] Et en fait, ce faisant, en apprenant à trouver les mots qui manquent, en fait, ce système élabore une représentation du langage, du texte qui contient la signification, la grammaire, la syntaxe, enfin tout, d'orthographe.
[00:14:19.320] Et donc ensuite, on peut entraîner le système à prédire des mots qui manquent.
[00:14:26.159] Alors, il ne fait pas une prédiction exacte parce qu'on ne peut pas, si je dis, le chat chasse le blanc dans la cuisine.
[00:14:35.239] Blanc, ça peut être quoi ? Ça peut être une souris, ça peut être un jouet, ça peut être le spot d'un laser ou n'importe quoi, ou une mouche.
[00:14:44.119] Donc, on ne peut pas exactement prédire le mot qui manque, mais ce qu'on produit, c'est une espèce de score pour tous les mots possibles dans le dictionnaire, ou une probabilité, des choses comme ça.
[00:14:54.719] A priori, il ne sera pas la chaise ni la table, le chat.
[00:14:58.719] Donc, il n'y a que certains mots qui sont possibles à certains endroits, etc.
[00:15:01.719] Alors ensuite, en fonction de l'architecture qu'on donne à ce réseau, alors déjà, ce qui est intéressant, c'est qu'on peut l'entraîner avec des textes de plusieurs langues.
[00:15:08.799] Et le système, en fait, apprend à représenter le sens du texte indépendamment de la langue, ce qui est assez extraordinaire.
[00:15:15.119] Tu vois, typiquement, ça, c'est un des trucs où tu dis, mais avant le lancement de ChatGPT, personne, j'imagine que vous l'aviez tous, ça, le changement.
[00:15:22.119] On connaît ça depuis 2018.
[00:15:23.520] Oui, mais en fait, il n'y avait rien d'aussi efficace que ce que...
[00:15:27.919] Enfin, tu vois, juste la traduction.
[00:15:30.880] Si je prends que ça et que j'isole ce truc, Google Trad ou tous ces trucs, ce n'était pas aussi bien que ce que fait OpenAI.
[00:15:38.239] Non, si, en fait, c'était mieux.
[00:15:39.440] Les systèmes de traduction spécialisés sont préentraînés de manière auto-supervisée de cette manière-là, mais ils sont plus efficaces pour la traduction que des systèmes un peu génériques comme ChatGPT.
[00:15:50.960] Mais ce qu'on constate, c'est que plus on entraîne des systèmes avec beaucoup de données, plus ils deviennent bons pour tout un tas de tâches, même des tâches pour lesquelles ils ne sont pas spécialisés.
[00:15:59.359] Donc, il y a un peu cet effet d'émergence.
[00:16:01.719] Mais par exemple, chez Meta, on a un système qui s'appelle Seamless, qui peut traduire 200 langues dans n'importe quelle direction et qui peut traduire en temps réel, c'est-à-dire avec un délai de deux secondes, qui peut faire texte à texte, texte à voix, voix à texte et voix à voix, y compris pour des langues qui ne sont pas écrites, ce qui est hallucinant.
[00:16:20.479] Et donc, ça, ce n'est pas encore dans les mains de tous les utilisateurs, mais bientôt, ça sera dans les lunettes intelligentes et on aura les sous-titres qui s'affichent si on parle à quelqu'un dans une langue étrangère.
[00:16:30.080] Est-ce que tu... J'imagine que non.
[00:16:32.280] Du coup, je ne sais pas, je vais répondre à la question avant de te la poser.
[00:16:35.799] Tu aurais envisagé qu'un LLM comme ça invente une langue et tu lui proposes une langue inventée peut-être par un autre LLM et qu'il la comprenne.
[00:16:50.840] Oui, absolument, c'est possible.
[00:16:52.239] En fait, ce genre d'expérience a déjà été fait où on met deux agents en relation l'un avec l'autre et puis on essaie de les entraîner à résoudre un problème et on construit la tâche de manière à ce qu'individuellement, les deux agents ne peuvent pas résoudre la tâche.
[00:17:05.680] Ils sont obligés de collaborer.
[00:17:07.319] On les entraîne au départ à utiliser l'anglais pour communiquer.
[00:17:09.920] Et en fait, ils finissent par inventer une espèce de langue efficace pour communiquer entre eux.
[00:17:14.160] C'est assez amusant comme expérience.
[00:17:16.640] Mais en fait, pour l'apprentissage auto-supervisé, c'est cette idée qu'on fait une corruption d'une entrée puis on entraîne le système à régénérer l'entrée complète.
[00:17:29.959] Alors, régénérer, ça veut dire prédire l'entrée.
[00:17:34.920] Et c'est pour ça qu'on parle de modèle génératif parce qu'on génère l'entrée, on régénère l'entrée.
[00:17:40.160] Et en fonction de l'architecture des systèmes qu'on entraîne pour faire ça, on peut ensuite leur donner un texte et leur demander de prédire le mot suivant dans le texte.
[00:17:51.640] Et ensuite, ce qu'on peut faire, c'est prendre le mot que le système a prédit.
[00:17:54.920] Alors, il produit une distribution de probabilités, mais on prend un des mots qui a une grande probabilité et on le met dans l'entrée.
[00:18:03.439] C'est-à-dire qu'on décale tous les mots de l'entrée et on lui rajoute le mot qu'il a lui-même prédit.
[00:18:08.680] Et ensuite, on lui demande de prédire le deuxième mot.
[00:18:12.160] On fait décaler ça dans l'entrée, le troisième mot, etc.
[00:18:15.000] Ça s'appelle la prédiction auto-régressive.
[00:18:17.479] C'est un vieux concept qui date des années 40-50, ce n'est pas récent.
[00:18:21.760] Mais avec ça, on peut faire produire des textes relativement longs, assez LLM.
[00:18:29.880] Ce qui explique que tu peux leur demander d'écrire des histoires ou des choses comme ça en disant...
[00:18:35.719] Ou de répondre à des questions...
[00:18:37.239] Pas loin sur la banquise, etc.
[00:18:38.880] Et puis voilà, ou répondre à des questions.
[00:18:40.400] Ou de traduire un texte en lui demandant traduit ce texte de français, anglais, etc.
[00:18:46.839] En fait, tout atteint l'instruction.
[00:18:48.680] Mais la limitation de ça, c'est que ces systèmes ne sont entraînés que sur du texte d'une part et d'autre part, ne peuvent pas vraiment réfléchir.
[00:18:56.839] Si on leur pose une question simple et qu'on leur dit, répond par oui ou non.
[00:19:00.239] C'est-à-dire, est-ce que 2 plus 2 égale 4 répond par oui ou non ?
[00:19:03.719] Ils vont répondre oui ou non.
[00:19:04.640] Et les ressources qu'ils vont dédier à ça, c'est simplement propager des signaux dans un réseau de neurones qui a 46 couches ou 92 couches, peu importe, et produit le token, le mot oui ou non.
[00:19:18.719] Avec une possibilité qu'il y ait une erreur en plus, dans le oui ou le non.
[00:19:21.959] Alors c'est possible qu'il y ait une erreur.
[00:19:23.680] Enfin bon, 2 plus 2 égale 4, est-ce que c'est vrai ?
[00:19:25.719] Bon, c'est facile à répondre.
[00:19:27.000] Maintenant, si on pose une question beaucoup plus compliquée, c'est-à-dire, par exemple, l'arithmétique avec des nombres assez importants, ou quelle est la racine carrée de machin, ou une question complètement insoluble, est-ce que, par exemple, tout nombre pair est la somme de deux nombres premiers, qui s'appelle la conjecture de Goldbach en mathématiques, qui n'est pas prouvée.
[00:19:45.239] C'est une hypothèse, une conjecture en fait, qui a l'air d'être vraie, mais qui n'est pas prouvée.
[00:19:48.760] Il n'y a pas de preuves.
[00:19:51.400] Et on dit, répond par oui ou non.
[00:19:52.839] Le système ne peut pas réfléchir à ça, il va toujours y dédier la mesure.

[00:20:00.000] même quantité de calcul que répondre à 2 plus 2 égale 4.
[00:20:03.440] Donc, il n'y a pas de possibilité vraiment de raisonnement dans ces systèmes-là, qui leur permet de réfléchir un peu plus à des questions compliquées et un peu moins à des questions moins compliquées.
[00:20:12.840] Donc, c'est là où on pourrait enlever le mot intelligence.
[00:20:16.799] C'est une intelligence qui est factice ?
[00:20:18.639] Elle n'est pas factice parce que ces systèmes sont entraînés avec une quantité de données tellement énorme qu'en fait, ils peuvent régurgiter des solutions qu'ils ont déjà apprises.
[00:20:27.240] Donc, 2 plus 2 égale 4, c'est dans leur mémoire, il n'y a pas de problème.
[00:20:31.240] Pour des chiffres, des nombres à plusieurs chiffres, ce n'est pas dans la mémoire.
[00:20:35.400] Donc là, ils sont obligés de faire appel à une calculatrice.
[00:20:38.560] Et maintenant, il y a des systèmes de ce type-là qui savent le faire.
[00:20:40.840] Ils savent que quand on leur pose un problème arithmétique, il faut qu'ils appellent une calculatrice.
[00:20:44.119] Plutôt que d'aller chercher dans les...
[00:20:45.959] Plutôt que de régurgiter ça dans leur mémoire.
[00:20:49.919] Mais il n'y a pas vraiment de capacité de raisonnement, d'invention, de choses nouvelles.
[00:20:56.080] C'est plutôt de la régurgitation.
[00:20:57.400] Donc, c'est un petit peu comme...
[00:20:59.959] Vous savez, dans une classe, quand il y a une classe de maths, il y a deux sortes d'écoliers ou d'étudiants.
[00:21:04.760] Il y a ceux qui comprennent vraiment ce qui se passe derrière les maths, et puis ceux qui apprennent par cœur.
[00:21:09.000] Et puis, on leur enseigne les additions, multiplications, subtractions, etc.
[00:21:12.919] Et puis, on leur pose un problème.
[00:21:14.120] Et puis, on vient de leur enseigner la multiplication.
[00:21:16.199] Ils vont appliquer la multiplication sans savoir si c'est la bonne chose d'affaire.
[00:21:19.199] Parce que c'est ça qu'ils viennent d'apprendre.
[00:21:21.639] Et donc, les LLM, aujourd'hui, sont un peu comme ça.
[00:21:24.720] Ils apprennent par cœur un peu.
[00:21:26.959] Ils savent, bien sûr, adapter une réponse, mais pas toujours.
[00:21:30.519] Donc, si on leur pose un problème un petit peu classique, un puzzle du genre, tu sais, il y a le problème de la chèvre, le chou et le loup qu'on doit transporter d'un côté de l'eau de la rivière avec un bateau qui ne peut transporter que deux choses à la fois.
[00:21:44.919] Et comment faire en sorte, quelle est la séquence pour faire en sorte que le loup ne mange pas la chèvre, ne mange pas le chou, etc.
[00:21:54.639] Donc, il ne peut pas être en même temps tout seul, etc.
[00:21:58.639] On pose ce problème-là à JJPT, il répond immédiatement, sans problème.
[00:22:02.040] Mais bien sûr, il rigurgite ça de sa mémoire, parce que c'est l'exemple-là.
[00:22:05.040] Il a été répondu à des endroits.
[00:22:06.480] Voilà.
[00:22:08.240] Par contre, on change un petit peu le problème pour que la solution soit différente.
[00:22:12.880] Et il rigurgite toujours la même réponse.
[00:22:15.119] Donc, ça veut dire qu'il ne réfléchit pas vraiment, en fait.
[00:22:17.240] Et si je change la chèvre par une antilope et puis que je le loue par un tigre ou un lion et puis le chou par je ne sais pas quoi, est-ce qu'il est capable de le comprendre ?
[00:22:31.320] Il est capable de comprendre parce que la représentation de chaque objet, en fait, la représentation d'une antilope et d'une chèvre va être similaire à l'intérieur du réseau neurone, etc.
[00:22:42.800] Il va faire une sorte de traduction, finalement, de la chèvre vers l'antilope ?
[00:22:47.399] Alors, on peut peut-être voir ça comme ça, mais c'est plutôt qu'en fait, une entité, enfin quelque chose, un objet, un mot est représenté par une séquence de nombres, on appelle ça un vecteur.
[00:22:57.000] Et les séquences de nombres qui représentent des entités similaires, en fait, sont similaires, donc peuvent être substituées l'une par l'autre.
[00:23:05.479] Et donc, un prédateur par un prédateur, etc.
[00:23:09.360] Donc, je pense que ce genre de chose marche.
[00:23:12.960] Il va comprendre que le chou ne mange personne, a priori, mais qu'il risque d'être mangé par plutôt la chèvre ou l'antilope.
[00:23:18.240] Enfin, OK.
[00:23:20.960] Et alors, ce qu'on dit là, c'est que...
[00:23:25.160] Je reviens sur la question d'intelligence.
[00:23:28.240] On est plus mémoire versus intelligence, quand même, dans le LLM, finalement.
[00:23:32.080] C'est plus régurgitation que raisonnement.
[00:23:34.839] OK.
[00:23:36.279] Et pourtant, ça donne de temps en temps un truc, une sensation d'intelligence qui est assez frappante.
[00:23:47.639] Mais de ce que je comprends aussi, vous êtes capable, chez Meta et potentiellement ailleurs, de la rendre un peu factice, notamment potentiellement en orientant vers, là, tu disais, une sorte de calculatrice ou d'autres choses selon les questions, de comprendre que ça, c'est pas dans la mémoire, mais c'est plus ailleurs qu'il va falloir aller chercher la réponse, c'est ça ?
[00:24:04.759] Il y a beaucoup de gens qui travaillent en ce moment sur essayer d'améliorer les performances des LLM en les augmentant avec des outils, soit, évidemment, des calculatrices, des systèmes de résolution d'équation, des choses comme ça, qui seraient appelés à bon escient, ou une technique qu'on appelle RAG.
[00:24:25.239] En anglais, ça veut dire Retrieval Augmented Generation.
[00:24:28.040] Et ça veut dire, en fait, interroger une base de connaissances, un moteur de recherche pour une question.
[00:24:34.839] Donc, si on pose la question à un LLM, quel était le PIB de la France en 2015 ?
[00:24:41.440] C'est très probable qu'il n'a pas ça dans sa mémoire.
[00:24:43.359] Mais par contre, il pourrait interroger un moteur de recherche ou aller chercher la réponse sur Wikipédia.
[00:24:48.600] Donc, des systèmes augmentés, des LLM augmentés, en fait, peuvent interroger un moteur de recherche, insérer la réponse, en fait, dans le prompt, c'est-à-dire la rajouter à la question qu'a tapé l'utilisateur, et ensuite transformer ça en une réponse en texte lisible.
[00:25:07.079] Donc, les agents, les assistants virtuels de Meta, Meta AI, font ça en utilisant des moteurs de recherche, des sources d'informations, etc.
[00:25:18.600] Et ça, c'est très utile.
[00:25:20.399] Mais quand même, ça ne lève pas complètement les limitations de ces systèmes-là au niveau raisonnement et autres.
[00:25:27.920] On a un peu le même problème pour les systèmes qui produisent du code automatiquement.
[00:25:31.399] Dans la mesure où c'est du code un petit peu stéréotypé, on peut utiliser une espèce de patron qu'on peut adapter.
[00:25:39.200] Les systèmes marchent bien, mais pour faire le design d'un système logiciel un peu nouveau, non, il n'y a plus personne.
[00:25:46.920] Et en fait, j'imagine que dès que tu es assez spécialiste dans un truc, tu vois souvent quand même assez vite la limite.
[00:25:55.160] Ce que je veux dire, c'est que moi, ce qui me scotch à chaque fois, c'est quand je lui dis, est-ce que tu peux, je ne sais pas, je vais lui dire, expliquer telle problématique à mes enfants de manière très simple ou à la manière de Victor Hugo, ou à la manière, c'est toujours wow, tu prends vraiment une claque.
[00:26:12.880] Cependant, quand j'écris, je ne sais pas, mes newsletters le dimanche, j'ai un raisonnement, j'ai une idée, j'ai envie de quelque chose.
[00:26:20.799] Ce n'est pas dingue, quoi.
[00:26:22.799] Cela dit, ce que j'adore, c'est la manière de penser.
[00:26:29.000] Qui est-ce qui m'a dit ça dans un épisode ?
[00:26:30.679] Mais de se dire que c'est la quatrième personne ou la cinquième personne dans un brainstorm, tu vois, et quand tu demandes des idées, tu as toujours un ou deux trucs qui peuvent vraiment changer la donne.
[00:26:41.679] Absolument.
[00:26:42.640] Ça, c'est dans de la mémoire, en fait.
[00:26:44.359] Et c'est ça, en fait, que les gens, dans les techniques génératives, que ce soit pour le texte, l'image, la vidéo, le son, etc.
[00:26:51.760] C'est une bonne manière d'avoir un interlocuteur avec qui on peut écouter, qui peut suggérer des idées ou inspirer, en fait.
[00:27:02.440] Donc ça, c'est très utile.
[00:27:03.640] Effectivement, on est un petit peu hypnotisé par le fait que ces systèmes manipulent la langue de manière très, très claire. On s'imagine que manipuler la langue, nécessairement, ça nécessite de l'intelligence.
[00:27:14.959] Mais en fait, c'est faux.
[00:27:16.079] C'est-à-dire que finalement, manipuler la langue, c'est simple.
[00:27:20.200] Et la raison par laquelle c'est simple, c'est que la langue est composée d'entités discrètes, des mots.
[00:27:26.640] Il n'y a qu'un nom fini de mot dans le dictionnaire.
[00:27:28.679] En plus, dans les LLM, on redivise ça à ce qu'on appelle les tokens, qui sont des sous mots, en fait.
[00:27:34.320] Il y en a typiquement, dans un LLM, 30 000 possibles ou quelque chose comme ça, 100 000 possibles.
[00:27:41.040] C'est utile pour des langues comme l'allemand, où on peut construire des mots en accolant des mots les uns aux autres.
[00:27:46.799] Donc, il faut pouvoir les décomposer.
[00:27:50.079] J'imagine tous les synonymes en français aussi que tu as, en fait, il y a des...
[00:27:54.640] Si tu fais ça automatiquement, parce que c'est vrai que les synonymes apparaissent dans des contextes similaires.
[00:27:59.320] Donc, il va automatiquement pouvoir faire ça.
[00:28:02.920] Mais on est hypnotisé par le fait que, à cause du fait que le système manipule la langue et que les seules entités avec lesquelles on est habitué, qui peuvent manipuler la langue, sont d'autres humains intelligents.
[00:28:14.799] On a l'impression qu'ils sont intelligents.
[00:28:16.200] Mais il ne faut pas se leurrer, c'est faux.
[00:28:19.760] Donc, en fait, tu dis que toutes ces personnes qui paraissaient très intelligents en utilisant des grands mots étaient, en fait, potentiellement des idiots.
[00:28:28.720] Il y a ça aussi, ce n'est pas exclu, des gens qui sont habitués à faire des arguments plutôt grandiloquents en utilisant la rhétorique et des mots savants plutôt qu'en fait, en discutant sur la substance.
[00:28:45.320] Oui, c'est peut-être une division qui est un peu un cliché, mais entre les scientifiques des sciences dures qui essaient de ne pas trop s'embarrasser de rhétorique et plutôt discuter de la substance.
[00:28:59.400] Et puis, les gens dont le métier est d'argumenter.
[00:29:05.440] Donc, si je lis...
[00:29:07.320] Merci pour ces explications, Yann, déjà, c'est très clair.
[00:29:11.880] Je n'avais pas exactement tout, tout, tout.
[00:29:14.679] J'avais compris un certain nombre de choses là-dedans, mais pas tout.
[00:29:18.440] Notamment le régressif, l'auto-régressif et puis aussi le supervisé, non-supervisé ou auto-supervisé.
[00:29:27.919] Ça, c'est aussi intéressant.
[00:29:32.159] Quand je t'écoute, donc, je comprends ce que tu peux dire par moment ailleurs.
[00:29:36.080] C'est que j'aimerais bien t'entendre le redire par tes mots.
[00:29:40.440] Mais tu prends deux exemples sur un enfant de zéro à six mois ou un exemple sur le permis de conduire qui sont, je trouve, assez passionnant.
[00:29:50.159] C'est dire qu'en fait, il manque des choses pour réussir dans la structure même, l'architecture même du LLM.
[00:29:58.320] On ne peut pas faire plein de choses.
[00:30:00.159] Donc, on est encore très loin, en tout cas, au moins là-dessus, de l'intelligence artificielle générale qui est prédite par beaucoup pour demain, dans trois ans, on ne sait pas.
[00:30:12.799] En tout cas, là, ce n'est pas du tout la bonne voie.
[00:30:15.280] Ça ne veut pas dire que c'est une mauvaise voie.
[00:30:16.479] Ça sert à d'autres choses.
[00:30:18.080] Ce n'est pas la bonne voie.
[00:30:18.960] C'est utile, mais c'est sur l'autoroute qui nous mène à l'intelligence de niveau humain.
[00:30:24.000] Je n'aime pas beaucoup la phrase l'intelligence générale parce que l'intelligence humaine est très spécialisée en fait.
[00:30:30.200] Mais disons, sur la voie qui va nous mener à ça, le LLM, c'est un peu une bretelle de sortie, c'est-à-dire que c'est très utile.
[00:30:37.599] Il faut développer ces technologies.
[00:30:39.080] Ça sert à plein de choses, mais ce n'est pas le secret final.
[00:30:45.119] C'est l'ingrédient qui nous manquait pour atteindre l'intelligence humaine.
[00:30:49.119] Et la raison de ça est multiple.
[00:30:53.000] Mais on peut se poser la question, pourquoi on a des systèmes comme ça qui puissent produire du texte dans le style Victor Hugo ou même passer l'examen du barreau ?
[00:31:02.359] Mais pourquoi on n'a pas de voitures autonomes qui se conduisent toutes seules niveau 5 sans intervention humaine ?
[00:31:08.559] Pourquoi on n'a pas de robots domestiques qui puissent faire tous les travaux, déménager, débarrasser la table, remplir la vaisselle, etc.
[00:31:16.880] Faire la cuisine.
[00:31:19.039] Et il s'avère que composer avec le monde physique, comprendre le monde physique est beaucoup, beaucoup, beaucoup plus compliqué que comprendre la langue.
[00:31:29.119] Ça, c'est très surprenant pour les humains, parce qu'on a l'impression que la manipulation de la langue, c'est ça qui requiert l'intelligence de niveau humain.
[00:31:35.840] Mais en fait, non, la langue, c'est facile.
[00:31:37.320] C'est simple à modéliser avec les LLM.
[00:31:40.719] Comprendre le monde physique, c'est beaucoup plus compliqué.
[00:31:43.599] Et c'est pour ça qu'on peut se poser la question de savoir.
[00:31:47.520] Enfin, le défi de la décennie qui vient dans la recherche en IA, c'est des systèmes qui puissent comprendre le monde physique, qui aient une mémoire persistante, c'est-à-dire un peu comme les humains.
[00:31:58.640] On a un truc spécial dans le cerveau qui s'appelle l'hippocampe, qui sert la mémoire à court terme et à long terme, mémoire factuelle, etc.
[00:32:07.320] Mémoire épisodique, mémoire de travail.
[00:32:10.239] Si on n'a pas d'hippocampe, on ne peut pas se rappeler de choses pendant plus d'à peu près 90 secondes.
[00:32:15.400] Il y a des gens comme ça qui ont eu des accidents vasculaires cérébraux ou des problèmes de hippocampe.
[00:32:20.479] Ils ne se rappellent pas de choses d'une minute à l'autre ou d'une heure à l'autre.
[00:32:25.559] Et il y a des systèmes qui sont capables de raisonner, donc de penser en passant du temps et l'énergie à un problème particulier et des systèmes capables de planifier.
[00:32:37.760] Alors, on a l'impression que ces quatre capacités, compréhension du monde, mémoire persistante, raisonnement et planification, sont quand même des composants essentiels de l'intelligence.
[00:32:46.840] Les LLM en sont essentiellement incapables aujourd'hui.
[00:32:49.799] Donc, on n'est pas du tout prêt à reproduire non seulement l'intelligence humaine, mais même l'intelligence des animaux, c'est-à-dire un chat de gouttière est très capable de comprendre le monde physique, a une mémoire persistante, peut certainement planifier et dans une certaine mesure, raisonner aussi.
[00:33:05.479] Donc, comment faire ?
[00:33:06.479] Et pourquoi ils ne savent pas lire ?
[00:33:07.880] Ils ne savent pas lire, mais finalement, parce que ce n'est pas utile pour un chat de savoir lire.
[00:33:11.559] Donc, l'évolution n'a pas construit cette capacité chez eux, ni de manipuler la langue, parce que ce n'était pas très utile pour eux.
[00:33:17.239] Et tout ça n'est pas inné en plus, on peut le dire.
[00:33:19.000] Il y a peut-être certaines choses qui sont innées dans tout ça un peu.
[00:33:21.799] Mais en revanche, c'est quelque chose qui l'apprend par le regard.
[00:33:25.440] Par le regard, l'audition, l'observation du monde physique.
[00:33:29.760] Voilà. Alors, on peut se dire...
[00:33:32.719] C'est un peu, comment dire, troublant, parce que les systèmes, les LLM qu'on entraîne, on les entraîne avec essentiellement la totalité du texte disponible publiquement sur Internet.
[00:33:43.520] La quantité de données est typiquement de 10 000 milliards de mots, de tokens.
[00:33:50.559] Donc, c'est un 1 avec 13 zéros derrière.
[00:33:52.640] Un token, c'est typiquement représenté par deux octets ou trois octets, quelque chose comme ça.
[00:33:55.799] Donc, ça fait une quantité d'informations qui est de l'ordre de 1, 2 avec 13 zéros derrière d'octets pour entraîner.
[00:34:03.840] Ça, ça nous prendrait environ 100 000 ans à lire tout ça.
[00:34:09.200] À raison de 12 heures par jour.
[00:34:12.119] Donc, c'est incroyable, quoi, comme quantité d'informations.
[00:34:14.520] On se dit, si on entraîne un système avec ce genre de données, ça va être vraiment intelligent.
[00:34:19.359] Mais en fait, non, parce que la connaissance qui est représentée par le texte, en fait, est extrêmement parcellaire et très restreinte aux choses qui sont intéressantes pour les humains.
[00:34:29.159] Mais il y a très, très peu de connaissances de base sur le monde, en fait, qui sont représentées par le texte.
[00:34:35.359] Et la manière dont on peut se convaincre de ça, c'est que les psychologues nous disent qu'un enfant de 4 ans et dans sa vie a été éveillé un total d'environ 16 000 heures dans les quatre premières années de la vie.
[00:34:52.559] Et si on essaie de mettre un chiffre sur la quantité d'informations qui est arrivée au cerveau, par exemple au contexte visuel ou par le toucher, c'est de l'ordre de 10 à la puissance 15 octets.
[00:35:05.000] Donc, c'est un 1 avec 15 zéros, c'est-à-dire 50 fois plus que la totalité du texte disponible publiquement avec lesquels on entraîne l'ALM.
[00:35:14.960] Donc, simplement en observant le monde pendant quelques mois ou même quelques centaines d'heures, on a plus d'informations, en fait, plus de données que la totalité du texte disponible sur Internet.
[00:35:26.679] Donc, ce que ça veut dire, c'est qu'on n'arriverait jamais à l'intelligence de niveau humain en entraînant simplement des machines sur du texte.
[00:35:32.919] Il va falloir les entraîner sur la vidéo, sur de l'image, de manière auto-supervisée.
[00:35:38.640] Et c'est là que le bas blesse, on ne sait pas comment faire.
[00:35:40.359] Enfin, maintenant, on commence à avoir des idées, mais c'est beaucoup plus compliqué que le texte.
[00:35:44.200] Je comprends ce que tu dis.
[00:35:46.159] Finalement, à un moment, on peut se dire, on aura des robots qui se baladeront, qui ressentiront les choses.
[00:35:51.000] On aura des lunettes qui vont enregistrer le monde pour comprendre des choses.
[00:35:56.000] Après, il reste le toucher, l'odorat, le oui, des tas de choses, des sensations.
[00:36:01.799] Finalement, j'enregistrais avec quelqu'un qui s'appelle le professeur Gérard Saillant, je ne sais pas si tu vois, de l'Institut de la moelle et du cerveau.
[00:36:07.119] Il disait qu'il y a aussi une...
[00:36:09.359] Il n'excluait pas, c'est assez intéressant, qu'il y ait potentiellement une forme de télépathie.
[00:36:13.679] C'est quand même quelqu'un de très sérieux, mais il dit en fait, le cerveau émet des ondes et on ne sait pas, il ne m'a pas dit que c'était le cas.
[00:36:19.559] Attention, je ne suis pas scientifique et vous l'êtes, lui et toi.
[00:36:24.400] Mais il me dit, en fait, ce n'est pas exclu.
[00:36:26.320] Enfin, on n'est pas, on ne sait pas exactement tout ce qu'on ressent et jusqu'où ça va et comment, ce n'est pas posé.
[00:36:33.239] Mais la question que je te pose avant de rentrer, justement, sur peut-être GEPA et d'autres types de choses que vous travaillez, c'est, est-ce qu'on ne pourrait pas envisager de tricher et de dire à la machine de lui rentrer textuellement tout ça ?
[00:36:48.520] Lui dire, en fait, quand je touche, il se passe ça, c'est très compliqué.
[00:36:52.280] Mais quand je vois, et dans les six premiers, se mettre à la place d'un bébé, dire, est-ce que ça ne peut pas être une option de lui dire, plutôt que de lui faire ressentir, ça va être compliqué, puis on ne va pas y arriver.
[00:37:02.400] Je vais tricher, je vais lui envoyer, comme sur les calculettes dont tu parlais tout à l'heure.
[00:37:05.760] C'est un peu ce que les gens font en ce moment.
[00:37:07.800] C'est-à-dire, il y a une phase, après le pré-entraînement sur les données publiques des LLM, on les ajuste, on les affine en leur posant des questions et puis ensuite, en leur faisant produire plusieurs réponses et ensuite, en engageant des personnes à donner un score à chacun des réponses possibles ou peut-être à proposer une meilleure réponse à la réponse en question ou simplement à faire en sorte qu'on puisse affiner la machine pour certains types de questions.
[00:37:45.959] Et si on engage suffisamment de milliers de personnes, qu'on dépense des centaines de millions là-dessus, ça coûte très cher de faire ça.
[00:37:54.359] Mais ces opérations qui sont déployées par Meta, Google, Microsoft et OpenAI, on arrive finalement à couvrir une bonne partie, une grande partie des questions que les gens peuvent poser et donc à peu près à couvrir un petit peu tous les usages.
[00:38:13.119] Mais c'est quand même insuffisant.
[00:38:16.199] Il y a toujours des questions qui vont sortir un petit peu des ornières et pour lesquelles le système ne va pas être entraîné, il va répondre à n'importe quoi.
[00:38:24.439] Parce qu'il n'a pas les capacités de raisonnement vraiment pour produire ses réponses lui-même.
[00:38:29.760] Et puis comme je le dis, j'ai utilisé le mot tricher, mais en fait, on ne raisonne pas, on triche, on lui donne des short-cuts, des raccourcis.
[00:38:39.760] Alors, il y a évidemment des systèmes aujourd'hui qui sont déjà déployés, dans lesquels on prend deux options.
[00:38:50.160] Je vais écrire la première.
[00:38:51.239] La première consiste à ce qu'on appelle Early Fusion en anglais.
[00:38:55.800] Donc, ça consiste à prendre des images ou des vidéos, à les découper en petits blocs, petits carrés et traiter ces carrés en fait comme des mots dans un texte.
[00:39:06.880] Et donc, quand on entraîne le système, on lui donne non seulement la séquence de mots de la question, mais aussi la séquence de patch d'images ou de vidéos ou d'audio tokenisés comme si c'était des mots.
[00:39:22.520] Et on entraîne le système à répondre à la question.
[00:39:26.880] Et du coup, le système a une espèce de vision de ce qui se passe.
[00:39:32.520] Alors ça, ça ne marche pas très bien.
[00:39:33.599] Il y a des systèmes qui ont été produits comme ça, à Meta, qui ne marchent pas très bien, aussi OpenAI et autres.
[00:39:39.439] Et puis, à DeepMind, ça ne marche pas très, très bien.
[00:39:42.920] Ce n'est pas vraiment satisfaisant.
[00:39:44.079] Je précise une chose, vous êtes 500 chez Faire, c'est ça ?
[00:39:46.760] C'est ça, à peu près, oui.
[00:39:48.119] À faire de la recherche sur ce genre de choses.
[00:39:50.400] Donc, il y a des équipes qui sont là-dessus.
[00:39:52.160] Il y en a d'autres qui sont sur du LLM, il y en a d'autres qui sont sur d'autres choses.
[00:39:54.760] Alors, LLM, on n'en fait plus trop, parce que maintenant, c'est dans les mains d'un groupe de produits qui s'appelle GenAI, qui produit.

[00:40:00.000] les LLM, c'est moins de la recherche, c'est du développement avancé, la recherche appliquée, on peut dire.
[00:40:06.560] Mais ça fait partie d'un groupe de produits qui produit Meta-AI, le système d'IA et puis aussi les systèmes de génération d'images et vidéos.
[00:40:14.040] Pour se rendre compte du nombre de personnes qui vont dire on arrête, on n'en fait plus, on va voir un peu qui fait quoi et comment.
[00:40:18.760] Ce n'est pas juste 12 personnes.
[00:40:20.160] Non, donc il y a à peu près un an, un peu plus d'un an, un an et demi.
[00:40:25.520] L'organisation de GénéAri a été créée au début 2023.
[00:40:29.680] Et le noyau dur de R&D Engineering de GénéAri, en fait, c'était une soixantaine de gens de fer qui ont été déplacés dans cette organisation pour un peu amorcer la pompe.
[00:40:41.040] Et puis ensuite, GénéAri a accru.
[00:40:43.279] Donc maintenant, c'est une très grosse organisation avec plus de 1000 personnes.
[00:40:46.439] On peut se dire qu'il y a quand même une petite réaction au succès d'OpenAI si on est en janvier 2023.
[00:40:52.320] Alors, la surprise n'a pas été technique, c'est à dire qu'on n'a pas été surpris trop par les performances du système.
[00:40:59.520] Parce qu'on avait des systèmes un peu similaires.
[00:41:02.000] Mais par contre, ce qui a surpris tout le monde, c'est l'enthousiasme et l'engouement du public pour ça.
[00:41:07.279] Et le fait qu'il pourrait y avoir un marché, enfin quelque chose à déployer qui serait utile aux gens, des assistants.
[00:41:14.680] Et on prenait notre temps un petit peu parce que justement, à cause de l'histoire de Galactica où on s'était fait arroser de vitrioles, on s'est dit bon, il faut peut être faire un petit peu attention.
[00:41:24.120] Google était un petit peu dans la même situation.
[00:41:25.760] On n'avait pas vraiment besoin de ça pour justifier la recherche en IA parce que Facebook est financé par la pub, etc.
[00:41:33.160] Donc, il n'y a pas une grosse pression pour générer des revenus à partir de ça.
[00:41:38.720] Alors qu'OpenAI, il y avait une grosse motivation pour le faire parce que c'est leur seul moyen de gagner de l'argent.
[00:41:45.239] Donc, c'est pour ça qu'ils ont été les premiers.
[00:41:46.720] Ce n'est pas vraiment une avance technologique.
[00:41:48.559] Ils en avaient peut être une petite, mais qui n'était pas...
[00:41:50.919] Personne n'est en avance de qui que ce soit depuis trois mois.
[00:41:54.639] Il n'y a pas vraiment de secret.
[00:41:56.279] Et puis, tous les gens qui travaillent là-dedans se connaissent tous.
[00:42:00.639] La moitié des dirigeants de DeepMind sont des anciens étudiants à moi.
[00:42:03.680] J'ai pas mal d'anciens post-docs et de collègues à OpenAI.
[00:42:06.680] Enfin, tout ça, ça circule.
[00:42:07.839] Donc, il n'y a pas vraiment de recettes secrètes que personne ne connaît.
[00:42:13.399] Ça ne dure jamais très longtemps.
[00:42:15.800] Mais ce qui a surpris, c'était effectivement l'engouement du public et le fait qu'il y ait peut être un marché à déployer.
[00:42:23.119] Donc, ça a suscité effectivement la création de l'organisation Gemini chez Google, GenAI chez Meta.
[00:42:30.000] Mais en fait, le résultat de ça, c'est que maintenant que GenAI peut se concentrer sur le développement de produits à base de LLM et d'IA générative, FAIR, c'est refocaliser sur la recherche à long terme.
[00:42:43.479] Quelle est la prochaine génération de systèmes d'IA capables de comprendre le monde, de raisonner, planifier, etc.
[00:42:50.039] C'est intéressant ce que tu dis, parce que ça veut dire que pour FAIR, en fait, je caricature évidemment, mais en fait, le LLM s'est plié.
[00:42:58.320] Maintenant, c'est parti dans une équipe produit.
[00:43:00.360] Ce n'est plus de la recherche.
[00:43:01.960] Un peu, oui.
[00:43:02.919] Et maintenant, nous, on va se concentrer sur autre chose.
[00:43:04.880] Voilà.
[00:43:05.360] Donc, ce que je dis aux étudiants maintenant, quand ils posent la question, qu'ils veulent, je ne sais pas, démarrer un doctorat ou s'intéressent à l'IA et de faire la recherche en IA, je leur dis, ne travaillez pas sur le LLM.
[00:43:17.160] C'est le passé.
[00:43:19.000] C'est le passé d'une part.
[00:43:20.000] Et d'autre part, c'est complètement dominé par l'industrie.
[00:43:24.520] Si vous n'avez pas accès à 10 000 GPU, vous n'allez jamais pouvoir faire quoi que ce soit d'utile.
[00:43:29.639] Si vous voulez rivaliser avec ça, même dans une start-up, il va falloir vous lever, comme Istral, 500 millions ou un milliard parce que vous allez dépenser tout votre budget en puissance de calcul.
[00:43:40.960] Exactement.
[00:43:41.479] En achat chez Nvidia.
[00:43:43.080] Voilà, ou en location en cloud.
[00:43:48.039] Et vous allez faire face à un Meta qui a 300 000 GPU, à Microsoft, qu'on a acheté une quantité similaire, et puis à Google qui a son propre hardware, le TPU. Donc, ça va être difficile.
[00:44:03.479] Il faut vraiment que vous soyez vraiment sûrs que vous êtes supérieurs au niveau intellectuel pour rivaliser là-dedans.
[00:44:10.440] C'est un peu compliqué.
[00:44:11.160] Mais donc, essayez de travailler plutôt sur des nouveaux concepts.
[00:44:15.800] Essayez d'inventer l'architecture de nouveaux systèmes d'IA qui vont dépasser les limitations actuelles.
[00:44:21.760] Donc là, en fait, on a repris la feuille blanche, quasiment.
[00:44:25.839] En fait, on a le LLM, il existe, il nous impressionne toujours.
[00:44:29.000] Il va faire des trucs bien.
[00:44:30.079] Je pense qu'il y a un des...
[00:44:31.040] Ce qui est intéressant, ce qu'on a appris avec OpenAI et le grand public, c'est peut-être des nouveaux cas d'usage qu'on n'avait peut-être pas prédits.
[00:44:35.880] Ou des...
[00:44:36.440] Je veux dire qu'une fois qu'on donne ça à tout le monde, en fait, on découvre que des gens l'utilisent d'une manière...
[00:44:40.839] Absolument.
[00:44:41.559] Donc ça, je pense que moi, je trouve ça assez cool et assez intéressant.
[00:44:44.640] Et c'est vrai que ça devient quand même un outil pour moi, pour beaucoup.
[00:44:50.559] J'étais avec Annabelle Brouron là, ce week-end.
[00:44:52.720] Je la voyais, faisait ses recherches où c'est sur...
[00:44:57.359] Enfin, sur ChatGPT 4 ou...
[00:44:59.440] Enfin, voilà.
[00:45:00.399] Ça devient un outil où beaucoup l'utilisent comme Google, comme les mails, comme plein de choses.
[00:45:04.959] Donc ça, c'est intéressant.
[00:45:06.839] Avant de revenir sur cette page blanche, c'est plus chez toi.
[00:45:10.279] J'ai compris, c'est plus chez Faire, mais c'est donc...
[00:45:12.279] Comment il s'appelle cette équipe?
[00:45:13.239] Gen AI.
[00:45:16.440] C'est quelque chose que vous avez choisi de pas ouvrir complètement au grand public comme Gemini ou OpenAI.
[00:45:23.399] Si, si, c'est complètement disponible.
[00:45:24.880] C'est même beaucoup plus ouvert.
[00:45:27.040] Alors, il y a deux choses.
[00:45:27.839] Il y a Lama, qui est un système open source, donc un LLM open source.
[00:45:32.640] Donc là, en fait, Lama a complètement démarré tout un écosystème autour de l'IA qui permettent à des petites et grosses entreprises ou même des associations d'affiner des LLM et de les utiliser pour leurs besoins, leurs applications verticales, leurs clients, etc.
[00:45:54.920] Et ça, c'est rendu possible par les plateformes open source, c'est-à-dire que vous pouvez télécharger Lama, donc c'est Lama 3 qui est le dernier.
[00:46:02.440] Mais le déclencheur de tout ça a été la distribution de Lama 2 qui s'est déroulée l'été dernier, l'été 2003, qui a permis de décimer complètement l'écosystème de l'IA qu'on voit, par exemple, à Paris, où il y a énormément de startups qui ont démarré dans l'IA.
[00:46:20.760] Une grande partie utilise Lama comme base ou Mistral, qui est aussi open source, ou quelques autres.
[00:46:28.000] Et ce que permettent les outils open source comme ça, donc on peut télécharger Lama ou Mistral et l'affiner, l'ajuster avec ses propres données qui peuvent être privées ou pas, avec ses fonds linguistiques, culturels, etc.
[00:46:48.119] Donc ça permet, par exemple, à des pays comme l'Inde de dire on va affiner Lama 2 pour qu'ils parlent les 22 langues officielles de l'Inde, ce que les systèmes de base entraînés en Californie ne font pas, ou entraînés à Paris, en l'occurrence, pour Lama.
[00:47:01.440] Et où ce qui permet à des gens, par exemple, un ancien collègue de FAIR, qui s'appelle Moustapha Cissé, qui était chercheur à FAIR, il y a quelques années est reparti en Afrique et depuis un an, a créé une entreprise qui s'appelle Kera Health, et qui utilise des LLM open source, ajusté pour parler pas seulement français, mais aussi le Wolof, qui est une des langues dominantes au Sénégal, et qui permet l'accès à de l'information médicale.
[00:47:32.320] C'est très difficile d'avoir un rendez-vous avec un docteur au Sénégal, parce qu'il n'y a que cinq docteurs pour 100 000 habitants.
[00:47:37.239] Et puis, ils sont tous dans les grandes villes.
[00:47:38.359] Donc, si on est dans un village, on n'a pas accès.
[00:47:42.079] Mais par contre, on voudrait bien parler à un docteur, avoir l'information sur des symptômes, etc.
[00:47:46.839] Donc, on peut parler à un LLM comme ça, qui a été réentraîné pour parler le Wolof et donner l'information médicale.
[00:47:53.880] Sachant que là-dessus, souvent, les grands Américains évitent de faire ce genre de choses, parce qu'ils ont peur des responsabilités qu'on prend légales sur...
[00:48:02.119] Ouh là là, je ne veux pas te faire un diagnostic, parce que sinon...
[00:48:04.480] Exactement, mais ce n'est pas quelque chose que Meta ferait.
[00:48:06.959] Mais par contre...
[00:48:08.399] Si tu le fais toi-même, c'est ton problème.
[00:48:10.200] Avoir ces moteurs open source disponibles, en fait, permet à tous ces gens d'être très inventifs sur les utilisations des LLM.
[00:48:17.880] Même chose en France.
[00:48:19.040] Il y a tout un tas d'entreprises qui utilisent ces LLM open source.
[00:48:23.399] Donc, ça, c'est très différent.
[00:48:24.399] Mais par biais d'API, là-dessus, on n'est pas forcément sur quelque chose...
[00:48:28.399] Qu'on utilise l'AMA comme OpenAI.
[00:48:32.640] Non, alors l'AMA, c'est pour des gens qui sont dans le développement d'applications, les développeurs, les chercheurs, etc.
[00:48:39.520] Au-dessus de ça, il y a un produit développé par Gen.AI, donc Amita, qui s'appelle Meta.AI, et qui est un agent intelligent avec qui on peut dialoguer à travers WhatsApp, Messenger ou Facebook, ou même Instagram.
[00:48:57.119] D'accord.
[00:48:58.440] Et c'est disponible si on va sur...
[00:48:59.919] Sur WhatsApp, je peux l'ajouter et parler avec lui, comme sur JGPT.
[00:49:05.840] Exactement.
[00:49:07.080] Et sur Facebook, c'est même plus amusant.
[00:49:09.119] Il y a des personnalités différentes, en fait, de ce LLM.
[00:49:12.080] Donc, par exemple, il y a un Dungeon Master, si on veut jouer à Donjons et Dragons, qui est personnalisé par Snoop Dogg.
[00:49:20.200] Pourquoi Snoop Dogg, je ne sais pas, mais c'est un LLM qui est basé sur l'AMA 2, qui a été affiné pour être expert en Donjons et Dragons.
[00:49:31.280] Extra.
[00:49:32.679] Et donc, tout un tas de choses comme ça.
[00:49:35.080] Et puis, ce système Meta.AI est disponible à travers les lunettes connectées intelligentes de Meta, donc les Ray-Ban Meta que je porte en ce moment sur le nez.
[00:49:46.760] C'est mes lunettes normales, en fait, correctives, et qui foncent au soleil, qui ont des caméras.
[00:49:55.159] Et donc, ils sont connectés à un LLM.
[00:49:58.159] On peut lui parler, lui poser n'importe quelle question.
[00:50:00.520] Et puis, on peut même lui demander de regarder la scène qu'on est en train de regarder et nous dire, nous donner des commentaires.
[00:50:06.000] C'est à dire, je ne sais pas, on regarde un menu en japonais.
[00:50:08.640] On peut lui demander...
[00:50:09.640] Et là, il va te parler, t'as des petits écouteurs.
[00:50:11.400] Des petits écouteurs par conduction, par le squelette, en fait, on ne sait pas entendre de l'extérieur.
[00:50:18.080] On peut jouer de la musique, etc.
[00:50:20.280] Et à terme, d'ici un an ou deux, il y aura des lunettes de ce type là avec un afficheur dans les lunettes qui permettra, par exemple, en temps réel, de produire des sous-titres.
[00:50:33.960] Si on parle, si quelqu'un nous parle dans une langue qu'on ne comprend pas, on aura les sous-titres automatiquement avec un délai de deux secondes ou quelque chose comme ça.
[00:50:41.000] On connaît des gens à la com' de Facebook.
[00:50:42.479] On va voir si on peut s'en procurer.
[00:50:44.719] Voilà, mais ce n'est pas pour tout de suite.
[00:50:46.280] La technologie est encore...
[00:50:47.520] Et puis, on pourra interagir aussi avec ces systèmes là, avec des bracelets, ce qu'on appelle des bracelets électromyographiques.
[00:50:54.840] Donc, ce que ça veut dire, c'est que c'est des bracelets qu'on porte sur les poignets, comme on dit normalement, qui ont des capteurs électriques qui capturent les courants électriques produits par les nerfs pour commander les muscles.
[00:51:05.280] Les muscles de la main ne sont pas dans la main, ils sont dans le bras.
[00:51:07.960] Et donc, avec ça, on peut inférer la position de la main.
[00:51:12.000] Et donc, on peut, en bougeant le pouce sur l'index, bouger un pointeur, par exemple, comme une souris, et puis cliquer.
[00:51:20.080] Et même, on peut taper au clavier avec les mains dans les poches.
[00:51:22.400] Donc, ça permettra un nouveau type d'interaction, en fait, avec les systèmes.
[00:51:27.599] Et à terme, toutes les interactions de tout un chacun avec le monde numérique se feront par l'intermédiaire d'un agent intelligent.
[00:51:34.239] C'est ce que fait...
[00:51:35.760] Ah non, du coup, ça me fait penser à Apple et son casque, là.
[00:51:39.880] Quand tu cliques ou que tu fais ces choses-là, c'est assez impressionnant.
[00:51:42.440] Quand tu l'essayes, tu l'essayais, non ?
[00:51:44.320] Non, mais ça, il a chassé Meta depuis deux ans, c'est Meta Quest 3.
[00:51:48.200] Il ne peut pas le chauffer, Yann Lecun.
[00:51:50.000] Apple essaie de grignoter, de rattraper leur retard.
[00:51:53.719] Et ils sortent un truc, à bord, qui est moins bon et qui est sept fois plus cher.
[00:51:57.440] Donc, non, je ne suis pas impressionné du tout, pas du tout.
[00:52:00.640] Comment il s'appelle le casque ?
[00:52:03.840] Evidemment, vous faites ça depuis assez longtemps.
[00:52:05.640] Le Quest 3, c'est le dernier.
[00:52:08.719] Et puis, il y a eu le Quest Pro avant et puis le Quest 2, bien sûr.
[00:52:12.640] Mais le Quest 3 est vraiment impressionnant au niveau réalité virtuelle, réalité mix.
[00:52:17.760] Et effectivement, interaction, on n'a pas besoin de manettes.
[00:52:20.799] On peut simplement avoir les mains, le système à faire la position des mains.
[00:52:25.000] Extra. On ne trouve pas encore son marché là-dessus, mais si ça se trouve, il y a un OpenAI qui va débarquer, qui va trouver votre marché avant vous.
[00:52:31.280] Mais bon, tout le monde en profite derrière, finalement.
[00:52:33.280] Le Quest 3 est disponible, ça coûte 400 euros, je ne sais pas quoi.
[00:52:37.280] Les lunettes d'intelligence, c'est 300 euros.
[00:52:39.159] Alors, la connexion avec MetaAI, le système, le LLM intelligent, n'est pas encore disponible en France ou en Europe.
[00:52:48.440] Pour l'instant, c'est été déployé, je crois, aux Etats-Unis, dans quelques pays anglophones.
[00:52:52.840] Mais il y a des questions de régulation, en fait, pour le déploiement.
[00:52:56.840] On est obligé de s'assurer qu'on respecte la législation en vigueur.
[00:53:02.119] C'est peut-être chose de la vie privée.
[00:53:03.599] En fait, c'est vrai que quoi qu'il arrive, tu te dis quand j'ai un bracelet, des lunettes et quelque chose avec un géant américain.
[00:53:11.719] Je ne vais pas te faire rentrer là-dedans, mais tu peux avoir une petite angoisse et te dire...
[00:53:16.719] On a ça avec les téléphones portables déjà, les smartphones sont connectés.
[00:53:20.719] Mais beaucoup de gens ont déjà ces angoisses, d'ailleurs.
[00:53:22.799] Google ou Apple, ça, à chaque seconde, exactement où on est par GPS.
[00:53:26.559] Enfin bon, c'est pas nouveau, c'est vrai.
[00:53:29.960] Et d'ailleurs, beaucoup des services, pas que Google et Apple, les gens qui ont des applis, s'il t'a autorisé, tombent là-dedans.
[00:53:37.559] Avant de revenir sur cette fâche blanche, j'ai une question pour un dev qui n'est pas un chercheur, qui fait du dev, je ne sais pas moi, sur du front, du bac, qui voudrait, en fait, se mettre à fond, mais déjà un peu, pour utiliser Lama 2, Lama 3 et faire des tas de trucs de ouf.
[00:53:59.799] Qu'est-ce qu'on lui recommande de faire ?
[00:54:01.440] Comment il apprend ? Est-ce qu'il faut faire un MOOC NYU ?
[00:54:05.080] Est-ce qu'il y a des ressources chez vous ?
[00:54:07.520] Comment... Est-ce que ça s'apprend tout seul sur YouTube ?
[00:54:10.559] Qu'est-ce qu'il faut faire ?
[00:54:11.400] Si on veut apprendre vraiment les bases du deep learning, par exemple, il y a tout un tas de cours disponibles gratuitement en ligne, y compris mon cours de deep learning à NYU, la version 2020-2021.
[00:54:24.280] La version 2020, je crois, a été traduite en 13 langues, c'est même disponible en français.
[00:54:28.239] Ce n'est pas périmé.
[00:54:29.359] Ce n'est pas périmé.
[00:54:30.320] Il y a peut-être un peu moins sur les transformeurs et les LLM que les dernières versions, mais sinon, il y a des blogs ou des publications séparées qui expliquent vraiment bien ce que c'est, c'est très accessible sur comment fonctionnent les deep learning, la propagation de gradient, les transformeurs, les LLM, etc.
[00:54:53.159] Donc, beaucoup de choses qui sont disponibles.
[00:54:55.919] Ensuite, il y a des bibliothèques logicielles qu'on peut utiliser, qui sont relativement faciles à utiliser.
[00:55:02.440] On n'a pas vraiment besoin de comprendre tous les détails pour arriver à les utiliser sous PyTorch.
[00:55:06.760] Donc, PyTorch, c'est un outil de développement de deep learning qui a été produit par Meta, qui n'appartient plus à Meta.
[00:55:17.200] Meta a transféré la propriété à la fondation Linux.
[00:55:19.840] Donc, c'est vraiment un projet communautaire.
[00:55:22.640] Et c'est universellement utilisé, excepté par quelques personnes à Google qui utilisent leur truc.
[00:55:29.400] Mais c'est vraiment universellement utilisé dans l'industrie et dans la recherche, surtout.
[00:55:34.919] Et alors, si on veut appliquer simplement LLM préentraîné comme Lama, on peut télécharger Lama 3 ou Lama 2 ou Mistral ou un autre.
[00:55:45.599] Et beaucoup de gens ont développé des moyens de déployer ces LLM sur des ordinateurs qui n'ont pas une dizaine de GPU de haute puissance qui coûtent une fortune.
[00:55:59.520] Mais en fait, de les faire tourner, même sur des ordinateurs portables ou sur des ordinateurs de, disons, d'état raisonnable ou avec un GPU de gamer, en utilisant des techniques de compression de ces réseaux-là.
[00:56:15.239] Donc, on peut les rendre plus efficaces après entraînement.
[00:56:19.080] Il y a plein de trucs comme ça.
[00:56:20.320] Donc, il y a un programme qui s'appelle Lama.cpp qui permet de faire ça, de faire tourner Lama sur des ordinateurs raisonnables.
[00:56:27.599] Sinon, si on ne veut pas rentrer dans ces détails, on peut utiliser Lama et autres à travers une API ou à travers un site qui sert de serveur.
[00:56:43.840] Donc, on ne le fait pas tourner chez nous, on le fait tourner chez un service cloud.
[00:56:47.159] Le plus simple, c'est probablement de passer par Hugging Face, qui est une entreprise franco-américaine qui offre ce genre de services.
[00:56:59.000] Donc, tous les modèles ouverts sont disponibles sur Hugging Face.
[00:57:01.760] Et puis, ils offrent un service qui est basé sur Amazon ou Google pour les faire tourner en remote, ou on peut aussi s'adresser directement à Amazon, à Azure chez Microsoft ou même à GCP chez Google pour faire tourner Lama sur leur cloud.
[00:57:20.520] C'est déjà installé, on n'a pas besoin de se prendre la tête.
[00:57:24.719] Ou on peut aussi l'utiliser à travers une API.
[00:57:26.359] Donc, Amazon, par exemple, offre Lama et tous les autres systèmes à travers une API, pareil pour Azure.
[00:57:32.719] Donc, c'est relativement simple, en fait.
[00:57:33.959] Et puis, on peut construire des applications de manière relativement simple autour de ça.
[00:57:37.640] Puis, si on veut quelque chose de vraiment customisé, on est une entreprise, on voudrait un LLM qui connaisse tous nos documents internes, qui puisse répondre à n'importe quelle question à nos employés.
[00:57:47.239] À ce moment-là, on peut employer les services d'une start-up dont c'est la spécialité d'affiner un LLM pour l'application verticale.
[00:57:54.160] On a reçu là-dessus notre ami, il y a quelques mois.
[00:57:58.239] Tu peux m'aider.
[00:58:00.599] Qui aide les entreprises qui est venu avec nous à Monaco.
[00:58:05.280] Je vois que tu ne m'aides pas.
[00:58:07.920] Je vais y revenir.
[00:58:09.400] Et un super épisode aussi dans lequel on est.
[00:58:12.839] Merci en tout cas de ces précisions.
[00:58:15.760] Donc, je reviens sur cette page blanche.
[00:58:18.439] On se dit finalement, le LLM, c'est un produit commercial.
[00:58:21.520] Moi, je fais de la recherche.
[00:58:22.719] J'ai compris que le texte, le langage n'était pas suffisant.
[00:58:30.800] Si je comprends bien, une des pistes, il y en a peut-être plusieurs, mais que vous travaillez avec GEPA notamment.
[00:58:36.880] Il y a une lettre à coller, GEPA, qui est de dire, plutôt que de masquer des mots, on va masquer des images dans des vidéos pour comprendre le monde.
[00:58:45.800] C'est ça, un peu ?
[00:58:47.000] Oui, c'est une vieille idée.
[00:58:48.199] L'idée d'utiliser l'apprentissage auto-supervisé pour permettre aux machines de comprendre comment fonctionne le monde.
[00:58:55.439] C'est un petit peu la même idée que pour entraîner les LLM, où on prend un texte et on masque certains mots.
[00:58:59.920] Et puis ensuite, on entraîne un système à prédire les mots qui manquent.
[00:59:02.479] On pourrait faire la même chose avec la vidéo ou les images.
[00:59:05.359] Donc on peut prendre des images, masquer certaines parties de l'image, entraîner un gros réseau de neurones à reconstruire l'image complète à partir d'une image partielle.
[00:59:13.119] C'est Stan Pollu de Dust, tu dois le connaître ?
[00:59:15.280] Ah oui, bien sûr.
[00:59:16.479] Stan, tu m'excuses, on t'embrasse, on t'adore en plus, mais j'ai eu un gros bug à moi-même, tu vois, ma mémoire de LLM.
[00:59:23.800] En anglais, on appelle ça Senior Moment.
[00:59:28.280] Senior Moment ?
[00:59:29.479] Senior Moment.
[00:59:30.680] Quand on est trop vieux, l'Hippocampe se durcit un peu.
[00:59:34.040] Je ne t'insulte pas, mais je n'en pense pas moi.
[00:59:38.560] Donc, on pourrait imaginer ça pour les images.
[00:59:41.640] On pourrait imaginer ça pour la vidéo.
[00:59:43.640] Et en fait, sur la vidéo, on montre, par exemple, une vidéo, un système.
[00:59:49.199] Et puis, on arrête la vidéo et on lui demande de prédire ce qui va se passer après.
[00:59:52.560] Alors évidemment, si, par exemple, la vidéo, c'est quelqu'un qui prend un stylo.

[01:00:00.000] le stylo est tenu au-dessus de la table et la personne ouvre les doigts, le stylo va tomber.
[01:00:05.440] On peut prédire que le stylo va tomber.
[01:00:07.400] A priori, il ne va pas s'envoler.
[01:00:09.000] Il ne va pas s'envoler, il ne va pas flotter dans l'air, il va tomber.
[01:00:12.760] On ne peut pas exactement prédire exactement comment, comment il va rebondir, etc.
[01:00:16.000] Est-ce qu'il va se casser la mine et autres, mais on peut prédire qu'il va tomber sur la table.
[01:00:19.840] Alors, l'idée, c'est peut-être qu'on pourrait faire la même chose qu'avec le texte, c'est-à-dire entraîner une machine à prédire ce qui va se passer dans une vidéo, et ce faisant, peut-être, ils vont réussir à comprendre que le monde est tridimensionnel, qu'il est composé d'objets, que les objets obéissent à la physique, qu'il y a des objets animés, inanimés, etc.
[01:00:38.360] Et un petit peu comprendre comment fonctionne le monde à la manière des enfants et des bébés animaux, des chiens, des chats, des rats, etc., des oiseaux.
[01:00:47.560] Et ça ne marche pas.
[01:00:49.480] Et ça fait dix ans qu'on essaye et ça ne marche pas du tout.
[01:00:52.000] Ça marche très bien pour le texte et ça ne marche pas pour l'image ni la vidéo.
[01:00:56.480] Ça marche un peu, ça marche chouette.
[01:00:58.599] On a des papiers là-dessus qui remontent à 2014, donc ça fait dix ans.
[01:01:02.439] Ce n'est pas une nouvelle idée.
[01:01:04.599] Et puis, c'est un concept qui est assez répandu dans les neurosciences, qui s'appelle predictive coding, donc codage par prédiction, dans lequel, effectivement, le cerveau peut-être représente le monde en essayant de faire de la prédiction et puis en encodant les erreurs de prédiction, c'est-à-dire ce qui n'est pas prédit est surprenant et ce qui est surprenant est intéressant.
[01:01:24.120] Donc, c'est une bonne manière de coder le monde, en fait.
[01:01:27.839] Donc, ces concepts sont très anciens, mais on n'a pas réussi à les faire marcher et on ne peut pas les faire marcher avec des architectures génératives, c'est-à-dire que ce qu'on fait pour le texte, c'est-à-dire prédire le prochain mot dans un texte ou les prochains mots dans un texte, on peut le faire parce que le texte, c'est simple et parce que c'est discret et parce qu'il n'y a qu'un nombre fini de possibilités d'un mot.
[01:01:52.120] La phrase que j'utilisais précédemment, le chat pour chasse, le blanc dans la cuisine, il n'y a que quelques mots qui sont possibles là-dedans et on peut produire un vecteur de probabilité qui dit probablement une souris, un spot laser, un jouet, etc.
[01:02:13.600] Mais on ne peut pas faire ça avec les images.
[01:02:15.279] C'est-à-dire que si je montre une vidéo et je demande à un système prédit ce qui va se passer dans une seconde, donne-moi une image qui représente ce qui s'est passé dans une seconde, ce n'est pas vraiment possible.
[01:02:25.720] On n'a pas une manière de représenter une distribution de probabilité sur toutes les images possibles.
[01:02:30.520] C'est impossible à faire.
[01:02:31.600] C'est un problème complètement intractable mathématiquement sur lequel les mathématiciens, les physiciens et les informaticiens, les statisticiens se cassent la tête depuis un siècle.
[01:02:39.960] Donc, ce n'est pas possible.
[01:02:41.919] On ne sait pas le faire.
[01:02:43.160] Parce qu'il y a trop de possibilités.
[01:02:44.679] Il y a trop de possibilités, exactement.
[01:02:46.119] Et on ne peut pas se permettre de représenter une possibilité, c'est-à-dire que d'entraîner le système à faire une seule prédiction parce que ce qu'il va faire, c'est qu'il va prédire une espèce de moyenne de toutes les choses qui sont possibles.
[01:02:59.639] Et donc, si c'est l'exemple du crayon qu'on laisse tomber sur la table, le crayon peut, à la fin, être dans tout un tas de positions et il va prédire une espèce de truc flou qui est une moyenne de tous les crayons dans toutes les positions possibles sur la table.
[01:03:15.039] Donc, ça ne marche pas du tout.
[01:03:16.880] Donc, on a essayé de résoudre ce problème-là avec des tas de système D, quoi, mais qui ne marche pas.
[01:03:25.839] Et puis, il y a quatre ans environ, j'ai complètement changé d'avis sur la question avec certains de mes collègues.
[01:03:35.199] Et ce qu'on a réalisé, c'est que ce qui marche dans l'image et donc ce qui commence à marcher dans la vidéo, ce sont des architectures non génératives.
[01:03:44.800] C'est-à-dire que le problème, c'est qu'on ne peut pas produire dans tous les détails, tous les pixels qui représentent la position du crayon sur la table.
[01:03:53.080] Mais par contre, on peut dire le crayon va tomber et il va être à plat sur la table.
[01:03:56.679] Mais ça, c'est une représentation abstraite de la réalité.
[01:04:00.600] Donc, on ne peut pas prédire tous les pixels dans la vidéo, mais on peut peut-être prédire une représentation abstraite du contenu de la vidéo.
[01:04:08.639] Donc, l'idée de JEPA, ça s'écrit J-E-P-A, et ça veut dire Joint Embedding Predictive Architecture.
[01:04:15.800] Comment on pourrait traduire ça en français ?
[01:04:17.399] Architecture Prédictive à Enchassement Joint.
[01:04:20.920] Je pense que ce serait le...
[01:04:23.440] Donc, A-P-E-J.
[01:04:27.079] Enchassement, voulant dire ?
[01:04:28.519] Enchassement Embedding.
[01:04:29.760] Embedding, OK, très bien.
[01:04:31.600] Je comprenais en anglais pour le coup.
[01:04:33.000] Voilà, donc qu'est-ce que ça veut dire Embedding ?
[01:04:34.279] Ça veut dire représenter une entrée, que ce soit un texte, une image, etc.
[01:04:41.200] en une liste de nombres qu'on peut voir comme un point dans un espace de haute dimension.
[01:04:46.880] Si on connaît un peu l'égypte linéaire, les espaces vectoriels.
[01:04:51.600] Donc, la notion d'embedding en mathématiques ou d'enchassement, c'est comment représenter des objets, quels qu'ils soient, par des points dans des espaces de haute dimension.
[01:05:03.320] Alors, qu'est-ce que ça veut dire le joint embedding ?
[01:05:05.920] Ça veut dire que si on prend une entrée, disons une image, et on lui fait subir une transformation ou une corruption, on va appeler l'image Y, on va l'appeler l'image corrompue ou transformée X.
[01:05:22.640] Une architecture générative voudrait reproduire Y à partir de X.
[01:05:26.880] C'est-à-dire faire une prédiction de Y, de tous les détails, tous les pixels, à partir de X.
[01:05:31.519] Ça marche pour le texte, pas pour l'image.
[01:05:34.559] Ce qui marche pour l'image, c'est qu'on prend Y et on le passe par un encodeur, donc un système qui va calculer justement un enchassement, un embedding, une représentation abstraite de l'image, qui va éliminer plein de détails sur l'image, mais qui va garder la substantifique moelle du contenu de l'image.
[01:05:51.920] C'est le crayon qui tombe, mais tout ce qui est derrière, qui n'est pas important, ou tout ce qui est...
[01:05:55.760] Voilà, il tombe sur une table en bois, et la texture du bois de la table n'a rien à voir avec le problème, donc on ne va pas représenter tout ça, tous les détails.
[01:06:03.359] Et puis, dans le fond, il y a, je ne sais pas, la télé qui joue un programme, on ne va pas prédire tous les pixels du programme de télé qui est en train de jouer.
[01:06:13.519] Donc on va éliminer tout un tas de détails qu'on ne veut pas prédire, et en fait, ne représenter que les choses qu'on peut prédire.
[01:06:19.799] Et on fait ça tout le temps, on ne s'en rend pas compte, mais en tant qu'humains et tous les animaux, on fait ça tout le temps.
[01:06:24.000] On ignore toutes les choses qu'on ne peut pas prédire et on ne se représente en fait que les choses qu'on peut comprendre.
[01:06:30.200] C'est une fois que j'ai entendu, mais on parle, quand tu conduis, s'il y a du vent, tu ignores les arbres qui bougent au fond.
[01:06:35.920] Ce n'est pas un truc que tu es en train de conduire, tu ne fais pas gaffe à ça.
[01:06:39.119] Voilà, alors que si on avait un modèle génératif dans la tête, il faudrait prédire le mouvement de chaque feuille.
[01:06:45.440] Chaque goutte qui tombe sur le pare-brise.
[01:06:47.600] Chaque goutte qui tombe sur le pare-brise, les petites vagues sur le lac.
[01:06:51.119] Il y a la 38ème goutte là, je ne l'ai pas prévu.
[01:06:54.839] Oh my god.
[01:06:56.079] Donc l'idée, c'est élever, trouver une représentation abstraite du monde dans lequel les détails imprédictibles sont éliminés, de manière à ce que le système puisse faire de la prédiction, mais que des choses importantes.
[01:07:11.920] Il y a un peu l'analogie dans la science, dans la physique par exemple.
[01:07:15.440] Qui aurait pu penser, au 17ème siècle, que pour prédire la trajectoire des planètes, la seule chose qu'il suffit de savoir, c'est les trois coordonnées de position de la planète et trois valeurs de vitesse, de vélocité.
[01:07:36.880] Avec ces six quantités, on peut complètement prédire la trajectoire de la planète, c'est-à-dire la taille, la forme, la masse, la couleur, la densité de la planète.
[01:07:48.160] Tous les détails sur la planète, s'il y a des êtres vivants ou pas, tout ça n'a aucune importance.
[01:07:51.480] La seule chose qu'il suffit de savoir, c'est ces six paramètres.
[01:07:54.079] Donc ça, en fait, c'est cette idée de comment élaborer une représentation abstraite du monde qui nous permet de faire des prédictions et savoir ce qui est utile et inutile.
[01:08:04.600] Ça, c'est vertigineux parce qu'en fait, tu vois, tout à l'heure, on ne comprend pas forcément tout quand tu parles d'un bébé ou d'un...
[01:08:11.279] En fait, le bébé, je pense que les premières fois qu'il reçoit des gouttes sur la tête, tu vois, il va dire une goutte de tiens, et puis la deuxième fois, et puis à la fin, il va dire un ballon, c'est mieux, tu vois, j'exagère, mais tu vois, il y a le truc qui est au centre de son attention et tout le reste est périphérique, quoi.
[01:08:26.279] Oui, absolument.
[01:08:26.920] Et ça, ça vient petit à petit.
[01:08:29.200] Et on est biaisé, enfin la nature humaine, et puis pour les animaux, c'est pareil, notre cerveau est construit pour prêter attention à certaines choses et pas d'autres, c'est-à-dire qu'on est...
[01:08:39.080] Les bébés humains prêtent attention beaucoup à ce qui bouge, parce qu'en général, il y a des choses plus intéressantes dans ce qui bouge.
[01:08:45.520] Ils prêtent attention aux choses qui sont surprenantes, c'est-à-dire que le cerveau prédit constamment ce qui va se passer.
[01:08:51.400] Et dès qu'une prédiction est violée, on est obligé d'y prêter attention parce que ça veut dire que notre modèle du monde était faux.
[01:08:57.479] Et donc, il faut l'ajuster.
[01:08:58.440] En fait, c'est comme ça qu'on sait que les bébés ont intégré certaines caractéristiques du monde.
[01:09:07.039] Si on montre à un bébé de 6 mois un jouet, une petite voiture sur une plateforme, donc qui se repose sur une plateforme, bon, le bébé de 6 mois voit un jouet bien coloré, il regarde un petit peu, mais pas trop.
[01:09:18.880] On pousse le jouet de la plateforme et le jouet semble flotter dans l'air, c'est-à-dire ne tombe pas.
[01:09:25.960] Un bébé de 6 mois, bon, va regarder, mais sans vraiment être intéressé parce qu'un bébé de 6 mois n'a pas encore compris que les objets tombent à cause de la gravité.
[01:09:32.960] Ça prend 9 mois.
[01:09:35.320] Donc, si on montre le même scénario à un bébé de 10 mois, il va écarquiller les yeux et se concentrer sur l'objet et se demander ce qui se passe en disant...
[01:09:43.159] Pourquoi l'objet flotte ?
[01:09:45.159] Le bébé de 9 mois ne parle pas, mais ils ont très, très bien compris tout un tas de détails de la physique intuitive.
[01:09:52.840] Et c'est ce genre d'apprentissage qu'on voudrait pouvoir reproduire avec les machines en les entraînant sur des vidéos, en leur entraînant à essayer de prédire ce qui va se passer dans une vidéo, mais à ne pas essayer de leur faire prédire tous les détails de l'image, mais de construire une représentation abstraite dans laquelle ils peuvent faire ces prédictions.
[01:10:11.239] Donc ça, c'est des modèles, c'est JEPA, c'est Gentleman in Productive Architecture, sont non-génératifs.
[01:10:17.039] Et ça, c'est un peu difficile à faire passer quand tout le monde, quand la mode technologique, c'est les modèles génératifs, Générative AI, même l'organisation chez Meta s'appelle Gen AI, Gemini s'appelle Gemini parce que c'est génératif, etc.
[01:10:36.359] Tout le monde parle d'IA générative.
[01:10:38.359] Et je dis aux gens, non, si on veut faire des programmes en IA, il faut abandonner l'idée de modèles génératifs.
[01:10:42.359] Ça ne peut pas marcher pour la vidéo.
[01:10:43.719] Si on veut que les modèles comprennent le monde, il faut utiliser ces JEPA et il faut arriver à les faire marcher.
[01:10:50.200] Donc pour l'instant, c'est là-dessus qu'on travaille, les faire marcher sur la vidéo et d'autres choses.
[01:10:54.799] Et dans le principe, à parté, je viens de comprendre pourquoi je faisais marrer les enfants, les bébés et pas les adultes.
[01:11:00.479] C'est parce qu'il suffit de faire et puis ils se marrent et tu les surprends, alors que ça ne marche pas.
[01:11:06.760] Oui, c'est surprenant pour les bébés.
[01:11:08.799] Par exemple, on peut jouer, en anglais, on appelle ça le peekaboo.
[01:11:12.799] On met ses mains devant son visage et puis on fait bouh, on enlève les mains et ça fait rigoler les bébés.
[01:11:18.799] En fait, j'essaye chez mes potes, ils disent qu'ils sont cons.
[01:11:23.520] Mais pour les bébés, ça marche bien parce que même la notion de permanence des objets n'existe pas pour le moment à la naissance.
[01:11:31.280] C'est des choses qu'on apprend très vite dans les trois premiers mois.
[01:11:34.919] Mais le fait qu'un objet existe toujours, même s'il est caché, n'est pas évident.
[01:11:41.559] C'est appris dans les trois premiers mois de la vie.
[01:11:45.239] Apparemment, chez les poussins, c'est inné, plus ou moins.
[01:11:49.000] Mais chez les humains, probablement, c'est appris.
[01:11:52.119] Et donc, c'est ce qui fait que peekaboo, c'est drôle.
[01:11:57.640] Mais en fait, ça paraît un peu anecdotique, tout ce qu'on dit là.
[01:12:00.119] Mais quand je dis que c'est vertigineux, c'est que...
[01:12:04.200] En tout cas, moi, dans cet épisode et dans cet échange avec toi, Yann, je comprends très bien la profondeur de ce que l'LM ne comprend pas, en fait.
[01:12:12.440] Et ce qui est intéressant aussi dans ce qu'on dit là, c'est que il n'est peut-être pas exclu pour toi que j'ai pas dans deux, trois, deux ans, tu l'abandonnes parce que vous disiez en fait, ça marchera pas.
[01:12:21.880] C'est pas la bonne voie. C'est ça la recherche.
[01:12:23.239] C'est possible. En fait, l'histoire de l'IA est jonchée de cadavres, d'idées de ce type là, où les gens se sont dit, bon, c'est comme ça qu'il faut faire.
[01:12:34.320] On va poursuivre cette approche.
[01:12:35.960] Et puis, ils se sont aperçus au bout de quelques années que, en fait, ça menait à une espèce de mur de pierre qu'on ne pouvait pas franchir.
[01:12:42.200] Une histoire intéressante dans l'histoire de l'IA, c'est donc dans les premières années de l'IA, dans les années 50, deux chercheurs qui sont des pionniers de l'IA, Newell et Simon, Herbert Simon et Alan Newell, qui étaient à l'université Carnegie Mellon.
[01:13:00.280] On proposait une méthode qu'ils appelaient, en toute modestie, le General Problem Solver, donc le solutionneur de problèmes général.
[01:13:13.479] Ils ont dit, c'est très simple, n'importe quel problème de raisonnement, en fait, peut être formulé comme un problème de recherche d'une solution du problème.
[01:13:21.159] Donc sinon, une bonne manière par programme de caractériser si un problème a été résolu ou pas.
[01:13:26.719] Est-ce que vous avez gagné aux échecs?
[01:13:28.280] Est-ce que vous avez trouvé le plus court chemin d'une ville à une autre, etc.?
[01:13:33.919] Tout ça, ça peut se réduire à un problème de recherche d'une solution dans un espace de solution.
[01:13:38.440] Et à partir du moment où il y a une caractérisation de la solution, il suffit de rechercher la configuration qui satisfasse à l'objectif.
[01:13:45.520] Et donc, dans la mesure où on peut formuler n'importe quel problème de ce type là, on peut juste écrire un programme qui va utiliser des heuristiques différentes pour résoudre des problèmes différents.
[01:13:54.960] Mais à la fin, c'est tous des variations de la même chose.
[01:13:58.000] Donc, ils ont écrit ce programme, puis ils se sont dit avec ça, on va résoudre tous les problèmes.
[01:14:01.479] Ce qu'ils n'avaient pas encore compris, c'est que d'abord, formuler un problème de cette manière là, ce n'est pas toujours très simple.
[01:14:08.479] Et que deuxièmement, certains problèmes nécessitent justement une quantité de connaissances, a priori, qui est assez importante et qui est très difficile à formuler.
[01:14:17.799] Troisièmement, que la plupart des problèmes nécessitaient des heuristiques de recherche de solutions spécifiques pour chaque problème.
[01:14:25.479] Et donc, ce n'était pas du tout général.
[01:14:27.159] Et puis surtout, le gros problème, c'est que la plupart des problèmes intéressants sont exponentiels, c'est-à-dire la complexité de calcul qu'on doit passer croît exponentiellement avec la complexité du problème.
[01:14:39.599] Et donc, ça veut dire que la plupart des problèmes intéressants sont complètement insolubles et intractables.
[01:14:43.239] Et ça a donné lieu en fait à l'apparition de la théorie de la complexité en calcul, etc., qui sont les bases de l'informatique théorique.
[01:14:50.520] Donc voilà, ils se sont heurtés à un mur.
[01:14:52.200] Et donc, bon, ça s'est un petit peu arrêté.
[01:14:56.280] Et puis, simultanément, il y avait des gens qui travaillaient sur, justement, des machines capables d'apprentissage qu'on appelle Perceptron à l'époque et puis d'autres.
[01:15:04.679] Et puis, ils se sont aperçus aussi au milieu des années 60 que c'était très limité.
[01:15:07.559] On ne pouvait pas faire des choses vraiment intéressantes avec parce qu'on ne pouvait pas entraîner des réseaux de neurones à plusieurs couches.
[01:15:13.400] Ça, c'est venu dans le milieu des années 80.
[01:15:15.679] C'est ce qu'on appelle le deep learning maintenant.
[01:15:19.159] Et puis, d'autres vagues d'intérêt dans les années 80, les gens ont construit ce qu'on appelait des systèmes experts, donc des systèmes capables de raisonnement logique.
[01:15:29.599] Mais le problème de ça, c'est qu'il faut spécifier toutes les connaissances a priori pour que le système soit capable de faire ce raisonnement, les règles de raisonnement, etc.
[01:15:37.880] Mais il y a eu un grand mode, un gros engouement au début des années 80 là-dessus.
[01:15:42.719] Le Japon a démarré un gros programme qui s'appelait ordinateur cinquième génération.
[01:15:46.039] On allait construire des ordinateurs spécialisés qui allaient pouvoir faire tourner des systèmes experts, etc.
[01:15:50.840] Échec total.
[01:15:52.200] Il y a une industrie qui s'est construite autour de ça, qui a construit des outils qui sont utilisés un peu partout maintenant.
[01:15:57.200] Mais on n'a plus la prétention de construire des machines intelligentes avec ce genre de modèles.
[01:16:00.880] Et puis ensuite, simultanément, aussi une vague d'intérêt pour les réseaux de neurones multicouches, parce qu'on avait trouvé une méthode qui s'appelle la rétropropagation de gradient pour entraîner des systèmes multicouches, ce qu'on ne savait pas faire les années 60.
[01:16:11.039] Et donc, ça a ouvert toute une communauté qui a commencé à travailler là-dessus.
[01:16:16.760] Et puis, au bout de dix ans, dans le milieu des années 90, c'est un peu tombé en désuétude, parce que ces systèmes-là étaient difficiles à faire marcher.
[01:16:23.039] Les ordinateurs n'étaient pas puissants, on n'avait pas beaucoup de sources de données, etc.
[01:16:26.200] C'était avant l'Internet.
[01:16:27.799] Et ces techniques-là sont réapparues.
[01:16:29.200] C'est ce qu'on appelle le deep learning maintenant, mais ça fait quinze ans.
[01:16:34.599] Donc ce sont des vagues après vague, après vague, après vague, tout en attendant à surfer quelques-unes finalement.
[01:16:39.280] Oui, finalement, et donc des vagues où on se dit ça y est, maintenant, on a trouvé le secret de l'intelligence.
[01:16:45.479] D'ici dix ans, on aura des machines aussi intelligentes que les humains.
[01:16:48.280] Et puis, on s'aperçoit que finalement, ces techniques sont limitées.
[01:16:50.479] Les LLM font partie de ça aussi.
[01:16:52.280] Il y a une vague d'intérêts maintenant qui va retomber.
[01:16:55.679] On va s'apercevoir dans l'imitation.
[01:16:57.080] On s'en est aperçu déjà.
[01:16:58.679] Et puis, la question, c'est qu'on travaille sur la prochaine vague.
[01:17:01.280] Est-ce que ce que tu me dis là, ce n'est pas débattu ?
[01:17:03.679] C'est-à-dire que sur le LLM, notamment quand on voit les millions investis un peu partout, les milliards, pardon, investis.
[01:17:12.479] Des dizaines de milliards.
[01:17:13.280] Des dizaines de milliards.
[01:17:14.880] Alors, il y a probablement, je le disais, du fait que beaucoup de gens l'utilisent, réfléchissent autour des cas d'usage qui vont être intéressants par le LLM.
[01:17:22.280] Mais le fait que l'intelligence artificielle générale, je crois que tu n'aimes pas trop ce terme, mais peu importe, arrive par le LLM.
[01:17:31.079] Tout le monde est d'accord.
[01:17:32.079] Ce ne sera pas le cas.
[01:17:32.880] Alors non, tout le monde n'est pas d'accord.
[01:17:35.079] Il y a des questions un petit peu philosophiques derrière.
[01:17:37.479] Donc, des philosophes qui travaillent sur la philosophie de la connaissance, etc.
[01:17:42.680] Et puis, la théologie et autres, ou les questions de la conscience, qui disent peut-être qu'on peut construire un système intelligent entraîné purement sur le texte.
[01:17:51.479] On n'a peut-être pas besoin d'entrées sensorielles, disons comme la vision, pour construire un système intelligent.
[01:17:57.680] Mais c'est une question conceptuelle, même philosophique, assez intéressante.
[01:18:01.680] Dans le domaine, tous les gens qui viennent de l'IA, par l'intermédiaire de la vision, la connaissance de la parole, sont tous absolument convaincus que les LLM sont insuffisants.
[01:18:12.079] Et on ne pourra pas arriver à l'intelligence humaine sans avoir une sorte de perception sensorielle, disons.
[01:18:20.280] Par contre, les gens qui viennent du traitement de la langue ou des linguistes, eux donnent beaucoup d'importance à la langue et pensent peut-être que c'est tout ce dont on a besoin.
[01:18:29.479] Certaines personnes disent oui, mais en fait, on peut traiter les images comme la langue, ça marchera, etc.
[01:18:34.280] Bon, il y a eu des expériences là-dessus qui n'ont pas très bien marché.
[01:18:36.880] Moi, je n'y crois pas du tout.
[01:18:37.680] On a même des projets à faire qu'on a arrêtés, en fait, parce que c'était un petit peu dans cette direction-là.
[01:18:43.880] Et on pense que ça ne marche pas.
[01:18:45.479] On a eu des projets aussi, justement, d'entraînement de systèmes d'autosupervision par reconstruction, en utilisant des modèles génératifs dans lesquels on prend une image, on fait une corruption, une transformation de l'image ou une vidéo.
[01:18:57.880] Et on entraîne le système à reconstruire ce qui manque dans l'image.
[01:19:02.479] Et on a arrêté aussi parce que ça ne marche pas bien, pour se refocaliser justement sur ces architectures de John ten Benning, les JEPA.
[01:19:10.079] Parce qu'on a beaucoup de données expérimentales qui montrent que l'apprentissage autosupervisé avec du John ten Benning, ça marche bien.
[01:19:17.479] On peut apprendre des belles représentations.
[01:19:19.479] Il y a un projet d'ailleurs qui sort de FAIR Paris qui s'appelle Dino, qui est utilisé par beaucoup de gens, qui permet en fait d'encoder des images, quelle que soit l'utilisation qu'on veut en faire.
[01:19:30.079] Si on veut faire la reconnaissance d'objets, de l'analyse d'images médicales.
[01:19:33.479] On avait un projet même en collaboration avec des gens en externe, dans lequel on prenait des...
[01:19:41.280] C'était dirigé par Camille Coupry à FAIR Paris.
[01:19:44.680] On prend des images satellitaires du monde entier.
[01:19:50.880] Et ce qu'on voudrait, c'est pouvoir estimer la hauteur de la canopée des arbres.
[01:19:56.079] Parce que ça permettrait d'estimer la quantité de carbone qui est capturée dans la végétation.

[01:20:00.000] Et pour certaines régions du monde, on a l'information de la hauteur de la canopée parce que des avions sont passés avec des radars etc. Donc on a l'information. Donc on entraîne un système de vision artificielle à prédire la hauteur de la canopée. On n'a pas assez de données pour entraîner un système complet donc on fait passer les images à travers ce système d'extraction de caractéristiques qui s'appelle DINO et ensuite on entraîne un petit réseau de roues dessus à prédire la hauteur de la canopée à partir de ces représentations. Et ensuite on peut l'appliquer à la terre entière et avoir une estimation de la totalité du carbone capturé dans la végétation dans le
[01:20:35.040] monde entier. Et voilà c'est un exemple d'utilisation de l'IA pour l'étude du climat. Et le LLM, alors ce qui est intéressant c'est que je comprends bien moi tu vois maintenant potentiellement la limite, je sais pas sur quoi bosse d'ailleurs Tesla, mais tu vois te dire si en effet le capteur d'une voiture automatique capte tellement d'informations non nécessaires et puis savoir laquelle est nécessaire en fait voir alors c'est vrai qu'on a vu des choses impressionnantes quand on voit sur trois voitures devant un frein mais ça semble potentiellement assez simple, la lumière rouge mais si elle n'est pas rouge
[01:21:11.919] et si c'est un autre et voilà mais être capable de comprendre et d'avoir du discernement pour se dire ça c'est une information intéressante ça c'en est pas une, en fait c'est infini. Oui mais dans le cas de Tesla, Wemo et autres donc les systèmes de conduite autonome et puis il y en a chez Dagger Benz qui sont faits par NVIDIA, un des acteurs dominants dans le domaine en est une entreprise israélienne qui s'appelle Mobileye, c'est eux qui font les grandes parties des systèmes de freinage automatique, de conduite automatique sur l'autoroute etc.
[01:21:46.720] Ces systèmes là trichent un petit peu, c'est à dire qu'ils sont entraînés de manière supervisée en grande partie, c'est à dire qu'on les entraîne à détecter des voitures, on collecte plein d'images avec des dashcam et puis on a des gens qui disent là il y a une voiture, là il y a un piéton, là il y a un vélo etc.
[01:22:03.599] Ils sont à telle distance, on peut aussi collecter des images venant de lidar, donc c'est une espèce de radar laser, pour voir la distance, ou avec la stéréo c'est à dire avec deux caméras on peut par triangulation estimer la distance.
[01:22:19.000] Et ensuite on entraîne un réseau de neurones à faire ces prédictions, en fait en général c'est des réseaux cognitifs, c'est un peu une invention qui date de 35 ans et qui détecte les objets qu'on a besoin de détecter. Donc là la tâche de savoir ce qui est intéressant ou pas en fait a été faite par les humains qui ont décidé de détecter certains objets.
[01:22:40.600] Donc il n'y a pas de langage là-dedans.
[01:22:42.600] Il n'y a pas de langage du tout, ensuite il y a une fois qu'on est détecté où sont les obstacles, ce qu'il faut, on peut aussi détecter, essayer de faire une carte des espaces qui sont traversables par la voiture et ensuite on peut essayer de planifier une trajectoire qui fait qu'on va pas se cogner dans un autre obstacle qui tire parti de la dynamique de la voiture, du volant, confort des passagers, etc. Et c'est comme ça qu'on fait des voitures autonomes. Mais on a besoin d'équipes de centaines d'ingénieurs en fait pour tirer parti de tous les cas particuliers. Donc on a par exemple un
[01:23:18.800] truc qui détecte un vélo, bon c'est très bien, si on a un vélo qui est de profil, bien sûr, et qu'on a une voiture, on se rapproche, on va se cogner dans le vélo, donc il faut freiner. Maintenant il y a des gens qui mettent leur vélo sur le haillon de leur voiture, qu'ils le suspendent parce qu'ils transportent leur vélo.
[01:23:38.880] Que doit faire un système de pilotage automatique dans ce cas-là ? Il va avoir peur et dire oh my god je vais renverser ce vélo, je dois le freiner.
[01:23:46.960] C'est la fameuse image de, qui était juste un mème à mourir de rire, mais de ce type qui, je crois que c'était un mec qui révélait sa femme, il est derrière un camion qui transporte lui-même des camions et le camion est à l'envers et puis tout d'un coup il se met à hurler et puis la femme elle l'ouvre et puis aaaah ! Et en effet tu te dis ben oui si tu vois un camion qui t'arrive dessus, ça pose un effet, c'est pas facile.
[01:24:08.479] Non et puis il y a des cas, des tas de trucs comme ça. Tesla se posait la question est-ce que pour améliorer la fiabilité, en plus des caméras, on pourrait utiliser des radars ? Donc les premières Tesla avaient des radars, ce qui permet d'estimer la distance des choses devant. Mais les radars ce n'est pas parfait parce que les radars, on est obligé en fait d'enlever tous les échos du radar qui viennent d'objets qui sont fixes. Donc les radars ne peuvent détecter que des voitures qui bougent et il y a eu un accident très célèbre de Tesla où un camion bien blanc était en travers de la route et donc pas détectable au radar parce que le radar enlève les objets fixes qui ne bougent pas par rapport au fond et la caméra était un peu hypnotisée
[01:24:50.959] par le camion blanc et donc n'a pas vu le camion et la Tesla est passée sous le camion et a décapité les voitures et les conducteurs. Donc ça c'est des cas rares et qu'il faut des équipes de centaines d'ingénieurs qui collèguent des milliers d'heures de données, des dizaines de centaines de milliers d'heures de données pour essayer d'avoir des événements rares comme ça et les traiter séparément. Comment se fait-il qu'un adolescent peut apprendre à conduire en 20 heures ? On n'a pas les techniques pour ça. Clairement il nous manque quelque chose. Donc la compréhension du monde, une espèce de physique intuitive, un certain sens commun qui permet non seulement aux
[01:25:34.200] adolescents de 17 ans d'apprendre à conduire mais même à un enroutant. On n'a plus beaucoup de temps alors je vais pas te retenir mais moi je trouve ça passionnant je pourrais y passer des heures encore. Il y a des choses qui te font peur dans l'IA ? Oui il y a une chose qui me fait peur c'est pas trop l'IA elle-même c'est plutôt la direction que pourrait emprunter le marché de l'IA. C'est à dire qu'il y a un futur dont j'ai parlé précédemment dans lequel toutes nos interactions avec le monde numérique se feront par l'intermédiaire d'assistants d'IA qui résideront
[01:26:12.679] dans nos smartphones, nos lunettes intelligentes, tous nos instruments portables et on va plus s'adresser à un moteur de recherche on va juste poser les questions à notre assistant. À un certain moment dans le futur ces assistants auront l'intelligence de niveau humain peut-être pour certaines tâches supérieures à l'humain. Alors il faut pas en avoir peur parce que travailler avec des gens plus intelligents que soi c'est bien. J'en suis le... J'en ai jamais fait l'expérience malheureusement. Moi en fait j'ai fait que ça, j'ai fait qu'embaucher des gens qui sont plus
[01:26:52.799] intelligents que moi. Non mais bon on peut se représenter bien sûr si on est je sais pas leader, directeur académique dans l'industrie ou politique certainement en politique on travaille avec un staff qui en général compose des gens qui sont plus intelligents que nous ou qui ont une expertise différente de la nôtre et qui peuvent nous conseiller sur des points importants. Donc il faut pas se sentir menacé par avoir à notre service des agents intelligents plus intelligents que nous. Au contraire ça va amplifier notre intelligence. J'aime bien essayer de dire de
[01:27:28.600] manière un peu optimiste avec des étoiles dans les yeux que ça pourrait mener à une espèce de nouvelle renaissance un petit peu ce qui s'est passé avec l'invention de l'imprimerie au 15e siècle où ça a suscité un intérêt pour les gens d'apprendre à lire et puis ça a disséminé des idées, la philosophie, le rationalisme, la démocratie, la science etc. et puis a mené à la révolution française, la révolution américaine, la destruction du système féodal etc. Bon c'est vraiment des révolutions importantes. Et il est possible que l'IA grâce au fait qu'il va augmenter l'intelligence
[01:28:06.959] humaine va apporter une espèce de nouvelle renaissance aussi, un renouveau en fait, un nouveau siècle des lumières amplifié. Donc ça c'est la vision hyper optimiste. Et c'est en partie grâce, pas forcément à l'IA générative et aux assistants, mais au fait que l'IA peut aider à faire progresser la science et la médecine beaucoup plus rapidement que ça a été possible jusqu'à présent. Y compris les LLM. Alors les LLM peuvent aider bien sûr mais c'est pas des systèmes par exemple qui prédisent le repliement des protéines pour essayer de faire la conception de nouveaux
[01:28:44.359] médicaments, des choses comme ça, ou de comprendre un peu les mécanismes de la vie. Ce ne sont pas des LLM. Mais par contre les architectures qu'ils utilisent sont très similaires à celles qui sont utilisées dans les LLM, c'est les transformeurs. Ils sont aussi entraînés de manière auto-supervisée.
[01:28:58.239] En fait on a à faire, on a fait certains travaux pionniers dans ce domaine. Donc traiter une séquence d'acide aminé comme une séquence homo, c'est la même chose. Mais ces systèmes sont quand même spécialisés. C'est à dire qu'ils sont faits pour spécifiquement calculer la conformation d'une protéine, savoir si une protéine peut se coller à une autre, aider à la conception de nouvelles protéines qui se colleraient à certains sites pour traiter certaines maladies, etc.
[01:29:31.719] Donc beaucoup de progrès.
[01:29:33.520] Ce que tu dis là, ce sont des choses qui sont orientées. Peut-être que je vais prédire un peu la suite ou pas d'ailleurs. On va voir si je suis... Non mais tu peux l'orienter dans tes recherches sur plein d'univers. Donc peut-être des armes, peut-être de la gestion des populations, de la manipulation, de plein de choses en fait.
[01:29:55.880] Alors les choses dont on pourrait avoir peur arriveront ou n'arriveront pas en fonction de la force de nos institutions démocratiques. C'est à dire que par exemple, on pourrait aujourd'hui, les technologies existent, mettre des caméras partout dans Paris et reconnaître les visages de tout le monde dans les lieux publics et fliquer les gens. Ça existe dans certains pays autoritaires.
[01:30:21.200] En France, bien sûr, ce serait une violation complète des lois sur la vie privée.
[01:30:27.000] Dans le AI Act de l'Union européenne, il y a une loi spécifique contre ça.
[01:30:32.320] On pourrait utiliser l'IA aussi pour des scores sociaux, qui est un petit peu en Chine, pour tout un tas de systèmes d'invasion en fait des libertés individuelles.
[01:30:40.679] Mais on a des institutions démocratiques assez fortes qui vont empêcher ça.
[01:30:44.599] Ensuite, pour la question des utilisations pour la défense et l'armement, certains de mes collègues un petit peu pacifistes disent qu'il faut absolument interdire les armes à base d'IA.
[01:30:54.520] Ça peut être dangereux, etc.
[01:30:56.039] Et en fait, ce dont on s'aperçoit, c'est qu'aujourd'hui, l'IA commence à être utilisé massivement pour la défense de la démocratie en Ukraine.
[01:31:03.239] Les Ukrainiens se défendent grâce à des drones qui sont pilotés par des gens, par radio et par vidéo.
[01:31:13.840] Mais la contre mesure que les Russes emploient contre ça, c'est de brouiller les communications vidéo, audio. Donc, on ne peut plus piloter les drones.
[01:31:20.919] Il faut que les drones soient autonomes pour aller faire sauter un tank ou un canon.
[01:31:25.440] Et donc, ils travaillent massivement sur ce genre de technologies.
[01:31:27.760] Ça utilise des technologies d'intelligence artificielle, de reconnaissance des formes, des réseaux cognitifs.
[01:31:32.440] Très probablement, je ne suis pas dans les secrets.
[01:31:35.280] Et beaucoup de gens, en fait, un de mes collègues, Antoine Borde, a quitté son poste à fer pour rejoindre une entreprise franco-allemande qui s'appelle Helsing et qui travaille sur l'intelligence artificielle pour la défense et qui est un petit peu critique pour la défense européenne.
[01:31:54.559] En fait, il y a des entreprises similaires aux Etats-Unis.
[01:31:58.239] Donc, ce n'est pas forcément mauvais d'utiliser ce genre de technologies pour la défense.
[01:32:02.640] Ça peut aider à la défense de la démocratie et du monde libre contre les régimes autoritaires, d'une certaine manière.
[01:32:12.280] Mais ce qui est important, c'est que dans la mesure où, dans le futur, on va tous interagir avec le monde numérique à travers des agents intelligents, on ne peut pas se permettre, justement, pour la défense de la démocratie, que ces agents intelligents soient produits par deux ou trois entreprises sur la côte ouest des Etats-Unis.
[01:32:29.599] Il va falloir avoir accès à une très large diversité d'agents intelligents.
[01:32:35.400] Et la diversité serait pour le fait que ces systèmes puissent parler une grande quantité de langues différentes, y compris dialectes, et accèdent ou comprennent la culture locale, les systèmes de valeurs, les biais politiques, etc.
[01:32:56.320] Il est impossible de construire un système d'IA qui n'est pas biaisé.
[01:33:00.039] De même qu'il est impossible de faire un journal ou un magazine qui n'est pas biaisé au niveau politique ou opinion philosophique, etc., ou système de valeurs.
[01:33:08.719] Et la solution qu'on connaît à ça, c'est qu'on ne va pas prendre ces nouvelles avec un seul journal ou un seul magazine.
[01:33:17.359] On va avoir une diversité de journaux et de magazines qui va permettre de choisir, en fait, un petit peu les biais pesés, etc., d'avoir une diversité de sources d'information.
[01:33:28.000] Il va falloir que la même chose arrive pour les systèmes d'IA, c'est-à-dire que les assistants virtuels devront être de sources très, très diverses.
[01:33:36.119] Et ça, ça ne peut exister que si on a des plateformes open source.
[01:33:40.719] Parce qu'on ne peut pas spécialiser, on ne peut pas enseigner un système propriétaire de parler Wolof ou une des 500 langues.
[01:33:49.640] On l'a vu aujourd'hui, en Inde ou ailleurs.
[01:33:53.960] Il faut que les systèmes soient open source pour que les gens dans les communautés locales, les gouvernements, les associations, les petites boîtes puissent affiner ces systèmes et offrir une très grande diversité de systèmes spécialisés.
[01:34:07.799] Meta a été résolument pris la décision d'open sourcer ces modèles d'IA, en partie pour cette raison.
[01:34:16.080] Je pense que pour moi, c'est la raison principale, mais aussi pour la raison que ça fait progresser le domaine plus rapidement.
[01:34:21.679] Si on est open source, ça rend des systèmes plus sécurisés.
[01:34:27.320] D'une part, on trouve les bugs plus facilement s'il y a plus de gens qui regardent.
[01:34:31.599] Ça essaime une industrie complète qui n'existerait pas sans les systèmes open source.
[01:34:37.400] Il y a 600 startups d'IA aujourd'hui à Paris.
[01:34:41.440] Elles utilisent presque toutes des modèles open source.
[01:34:44.479] Donc, c'est vraiment important.
[01:34:47.640] Le danger, c'est qu'à cause de lobbying, peut-être de réglementation, peut-être de dynamique du marché, qu'en fait, le marché soit capturé par deux ou trois entreprises et qu'on n'ait pas accès à une grande diversité d'assistants d'IA.
[01:35:01.359] Je pense que c'est ça le plus gros danger à court terme.
[01:35:03.440] Puis, il y a des dangers plus petits, mais qui sont plus anciens.
[01:35:06.080] Est-ce qu'on peut utiliser l'IA pour disséminer la désinformation, des fake news, etc.?
[01:35:10.479] Mais ça, en fait, ce n'est pas de nouveaux problèmes.
[01:35:12.119] On sait déjà un petit peu les contrôler à Facebook.
[01:35:16.200] J'imagine que vous êtes au cœur de ces choses-là.
[01:35:20.719] En effet, c'est intéressant de voir ça aussi avec la masse de données.
[01:35:24.440] Et ça utilise l'IA massivement.
[01:35:25.840] J'imagine.
[01:35:26.799] J'imagine.
[01:35:28.159] Parce qu'on a vu, en effet, tous ces reportages sur notamment le contrôle des choses qui sont postées.
[01:35:35.599] Les données sont tellement énormes.
[01:35:37.400] En fait, il y a un chiffre qui est vraiment important.
[01:35:39.400] Fin 2017, on a fait une statistique.
[01:35:41.919] On a essayé de voir, de détecter tous les contenus de discours d'ON sur Facebook.
[01:35:52.760] Et on a des systèmes automatiques d'intelligence artificielle, mais assez primitifs, fin 2017, qui suppriment automatiquement ces discours d'ON avant que qui que ce soit ne les voit.
[01:36:03.880] Et la proportion de discours d'ON supprimés automatiquement était d'environ 23 %, si je me rappelle bien.
[01:36:09.119] Dans ces derniers trimestres 2017.
[01:36:13.599] Ça veut dire que les autres, le reste, les 77 %, étaient en fait publiés sur Facebook et puis ensuite signalés par des utilisateurs et ensuite examinés par des modérateurs humains qui décidaient de les supprimer en étant des discours d'ON.
[01:36:32.520] Ces discours d'ON sont illégaux en Europe, certains.
[01:36:34.679] On ne peut pas faire la propagande néo-nazie, etc.
[01:36:36.799] Ce n'est pas illégaux aux États-Unis, mais on applique un peu les mêmes règles partout.
[01:36:40.200] Et ce pourcentage, fin 2022, donc cinq ans plus tard, est passé à 96 %.
[01:36:47.919] Et la différence, c'est les transformeurs avec apprentissage auto-supervisé, c'est-à-dire exactement la même technologie qui est utilisée dans les LLM, a amélioré ce genre de score d'une manière absolument incroyable depuis 2017.
[01:37:05.520] Les transformeurs, ça date de 2017-2018.
[01:37:07.880] L'apprentissage auto-supervisé est généralisé à peu près à la même époque et en fait, ça a permis d'entraîner comment, par exemple, détecter que des gens s'échangent des arguments pour s'entretuer dans une région où il y a une guerre civile, qu'ils parlent un dialecte local, qu'on ne parle pas, qu'aucun des modérateurs humains ne parle parce qu'ils sont dans un pays où on ne peut pas s'installer parce que le gouvernement ne nous aime pas.
[01:37:31.760] Donc, c'est vraiment compliqué de faire ce genre de modération de contenu.
[01:37:35.119] Mais grâce aux transformeurs avec apprentissage auto-supervisé, maintenant, on peut entraîner ces systèmes-là à comprendre à peu près n'importe quelle langue dans le monde et donc, faire en sorte que les gens s'entretuent moins.
[01:37:47.040] On ne peut pas, malheureusement, avec les réseaux sociaux, empêcher que les gens s'entretuent.
[01:37:50.199] On voudrait bien, mais on n'a pas cette superpuissance.
[01:37:54.119] Et puis, protéger le processus électoral, les élections, la démocratie, etc.
[01:38:00.319] On avance d'une élection.
[01:38:01.719] Il faut un peu essayer de calmer le jeu, que les gens ne s'aiment pas les disanier, etc.
[01:38:08.199] J'ai deux questions avant de te laisser partir.
[01:38:09.920] Une très rapide.
[01:38:11.479] Alors, tu as un livre qui vient de sortir qui s'appelle Quand la machine apprend.
[01:38:15.119] Si tu avais, toi, un livre à me recommander, ce serait lequel ?
[01:38:19.319] Alors, en fait, ce livre a été écrit il y a presque cinq ans, maintenant.
[01:38:24.160] Ok, mais j'ai vu que tu le signais hier à Vivatech.
[01:38:25.959] Alors, je me suis dit, bon, tu as peut-être un autre livre plus récent de ta part.
[01:38:29.719] Alors, ce livre est sorti en 2019, en français.
[01:38:36.880] Je l'ai écrit en français.
[01:38:38.479] J'ai eu de l'aide.
[01:38:40.119] Édité chez Odile Jacob.
[01:38:42.439] Et l'année dernière, enfin, il y a quelques mois, on a sorti une version poche.
[01:38:47.959] Ok, c'était relativement récente.
[01:38:49.520] Très bien.
[01:38:50.479] Et effectivement, j'ai fait une séance de dédicaces à Vivatech.
[01:38:54.959] On a dû couper la queue.
[01:38:56.640] Enfin, il y a eu une heure et demie queue.
[01:39:00.119] Il y a eu beaucoup trop de gens qui étaient...
[01:39:02.359] Donc, j'ai un fan club.
[01:39:05.319] Je ne suis pas président.
[01:39:08.079] On les invite, on les salue s'ils sont là encore.
[01:39:10.239] Je les salue, je les remercie.
[01:39:12.199] J'ai entendu plein d'histoires très émouvantes de gens qui m'ont dit j'ai lu votre bouquin et ça a changé ma vie.
[01:39:19.680] J'ai complètement changé ma carrière.
[01:39:21.239] Je me suis mis à apprendre l'IA, tout ça.
[01:39:22.959] J'ai créé une start-up, j'ai repris des études.
[01:39:25.560] Donc, c'est très émouvant.
[01:39:27.160] Ilon M.
[01:39:30.439] Il avait dit de me recruter, mais ça n'a pas marché.
[01:39:35.640] Ça fait longtemps.
[01:39:37.959] Et donc, c'est émouvant de savoir quel impact on peut avoir.
[01:39:45.040] C'est un petit peu compliqué pour moi à Vivatech, parce que je ne pouvais pas faire 5 mètres sans que les gens me demandent de faire des selfies avec eux.
[01:39:49.760] Mais c'est pareil, je trouve ça charmant.
[01:39:51.239] Voilà.
[01:39:53.880] Mais...
[01:39:57.239] J'ai perdu le fil.
[01:39:58.000] C'est un livre que tu aurais à me recommander, ça peut être...

[01:40:00.000] Peu importe, je sais que t'es dans plein d'autres choses, tu fais de la musique, j'ai vu que tu faisais du modélisme, t'as un site de modélisme, on voit ton fils Kevin, c'est ça ?
[01:40:07.000] Bon, c'est un site un peu ancien.
[01:40:09.000] C'est à mourir de rire, mais je me demande comment t'as le temps de faire tout ça, toutes ces passions dont tu me parlais, t'es arrivé, tu me parles de mes caméras, tu me dis, je ne sais pas comment tu fais tout ça, j'aurais pu rentrer là-dedans, mais on n'a plus le temps.
[01:40:21.000] Mais donc, un livre qui t'a marqué, si t'avais l'opportunité d'offrir un livre à tout le monde, ce serait lequel ?
[01:40:27.000] Ça va peut-être te surprendre, mais c'est un petit livre écrit par Richard Feynman, qui s'appelle QED, donc Q-E-D en anglais.
[01:40:37.000] Je ne sais pas s'il y a une traduction française de ce livre, je pense qu'il doit y en avoir une.
[01:40:40.000] Donc QED, ça veut dire Quantum Electrodynamics, donc électrodynamique quantique.
[01:40:45.000] Et Feynman a ce don d'expliquer en termes très simples des concepts extrêmement compliqués de physique quantique, etc.
[01:40:54.000] Et d'expliquer en fait des phénomènes qu'on observe tous les jours.
[01:40:57.000] Donc pourquoi, par exemple, quand on met un film d'huile sur de l'eau ou sur une surface plate, on voit des iridescences colorées ?
[01:41:07.000] Tu es en train de m'ouvrir le truc de la physique quantique et de l'IA, mais je ne vais pas aller là-dedans parce que je vais me faire gronder après, pardon.
[01:41:13.000] Ok, je vais te dire deux mots. Je ne crois pas à l'application du calcul quantique à l'IA, et en fait, je suis très sceptique sur le calcul quantique.
[01:41:21.000] Ok, très bien. On en fera un débat avec nos amis de Pascal.
[01:41:26.000] Voilà, exactement, il y a quelques jours.
[01:41:29.000] Dans un prochain épisode.
[01:41:32.000] C'est intéressant cette question que je pose à chaque fois quand même à mes invités, mais je pense que chez toi, elle pourrait avoir une autre portée.
[01:41:38.000] Parce que, en effet, tu as appris plein de choses depuis.
[01:41:42.000] Si tu avais l'occasion, ton doctorat, tu l'as fait où ? Pierre et Mercurie ?
[01:41:47.000] Ça s'appelait Pierre et Mercurie à l'époque. Maintenant, ça fait partie de Sorbonne.
[01:41:51.000] Sorbonne. Si tu avais l'occasion de croiser Yann Lecun au moment de l'obtention de ton doctorat et de te dire quelque chose, tu pouvais te glisser un mot derrière l'oreille.
[01:42:02.000] Qu'est-ce que tu dirais à ce moment-là ?
[01:42:04.000] Je me dirais, si tu vas aux Etats-Unis, tu vas apprendre que tu ne devrais pas avoir de complexes, de complètes infériorités, parce que tu n'es pas allé dans une des deux ou trois écoles les plus...
[01:42:19.000] Princeton, Stanford ?
[01:42:21.000] Ou même en France, Normale Sup, Polytechnique Centrale.
[01:42:25.000] J'ai fait une école qui s'appelle Essier, qui est une bonne école, mais qui n'est pas dans les super top, dans l'espèce de hiérarchie qu'elle en croit ou pas.
[01:42:35.000] Mais dans laquelle j'ai appris plein de choses, en fait.
[01:42:38.000] Ce qui a été très bien pour moi.
[01:42:41.000] D'ailleurs, je suis dans leur conseil scientifique maintenant.
[01:42:45.000] Je suis même président du conseil scientifique de l'Essier.
[01:42:48.000] C'est une bonne école.
[01:42:49.000] Mais, dans le général, elle n'est pas complexe.
[01:42:53.000] J'ai appris ça quelques années plus tard à Bell Labs, où je me suis aperçu, en fait, qu'aux Etats-Unis, on enseignait aux jeunes et aux étudiants de ne pas avoir de complètes infériorités, de ne pas hésiter à poser des questions stupides, de ne pas hésiter à se lancer dans des domaines dans lesquels on n'a pas de diplôme, on n'est pas nécessairement spécialiste, etc.
[01:43:16.000] Je me suis un petit peu essayé la physique, par exemple, dans les premières années où j'étais à Bell Labs, parce qu'une grande partie du labo dans lequel j'étais était constitué de physiciens.
[01:43:23.000] J'ai écrit deux ou trois articles publiés dans des journaux de physique, sur des physiques un petit peu fondamentales.
[01:43:32.000] En fait, il faut être ambitieux, avoir l'ambition, c'est-à-dire se fixer un but à très long terme, qui pour moi a toujours été découvrir le mystère de l'intelligence et en tant qu'ingénieur, aussi construire des machines intelligentes, parce que je pense que c'est la seule manière de valider si des idées abstraites fonctionnent, décrypter un peu comment l'intelligence a émergé chez les humains, chez les animaux, en la reproduisant dans les machines.
[01:43:59.000] Et ensuite, essayer de voir quel chemin je peux prendre, quel pas je peux faire en avant vers ce but à long terme.
[01:44:07.000] Et évidemment, remplir ce but à long terme peut prendre 10, 20, 30, 40 ans, mais on peut faire des progrès qui, à la fin, auront un impact à relativement court terme.
[01:44:19.000] Par exemple, comment construire des machines intelligentes ?
[01:44:21.000] Pour construire des machines intelligentes, on peut soit les concevoir soi-même, soit faire en sorte que ces machines se conçoivent par apprentissage.
[01:44:27.000] C'est un peu l'idée.
[01:44:28.000] Donc, très rapidement, je me suis dit, je ne suis pas assez intelligent pour construire des machines intelligentes.
[01:44:32.000] Par contre, peut-être si elles peuvent apprendre, ce qui est le cas de tous les êtres vivants, peut-être elles peuvent, par auto-organisation, en fait, devenir intelligentes.
[01:44:41.000] Donc, l'apprentissage des machines, c'est vraiment le truc qu'il faut essayer d'attaquer.
[01:44:47.000] Donc, j'ai regardé la littérature qui s'arrêtait dans les années 60, parce qu'il y a eu des échecs sur les limitations, et je me suis dit, mais quand même, ça a l'air intéressant comme concept, il faut essayer de pousser.
[01:44:56.000] Donc, j'ai essayé d'entraîner comment résoudre le problème qui n'avait pas été résolu à l'époque, d'entraîner des réseaux de neurones à plusieurs couches.
[01:45:02.000] J'ai trouvé une idée qui était très similaire à ce qu'on appelle maintenant la rétropropagation de gradient.
[01:45:07.000] Je me suis aperçu qu'il y avait deux, trois autres personnes dans le monde qui s'intéressent aux mêmes choses, dont Geoffrey Hinton et quelques autres.
[01:45:13.000] Et puis, quand j'ai fini mon doctorat là-dessus, je suis allé travailler avec lui pendant un an.
[01:45:19.000] Et puis, j'ai développé les réseaux cognitifs qui sont des architectures de réseaux de neurones qui sont un peu inspirées de la biologie, de l'architecture du contexte visuel.
[01:45:28.000] Ce que je me suis dit, la première chose qu'on peut faire avec ces trucs-là, c'est essayer de faire de la reconnaissance d'images, de la reconnaissance des formes.
[01:45:34.000] Et à l'époque, les seules images pour lesquelles on avait des bases données, pour lesquelles on peut utiliser l'apprentissage, c'était des chiffres ou des lettres scannées.
[01:45:44.000] En informatique, tu veux dire qu'elles avaient été numérisées à ce moment-là.
[01:45:48.000] Il n'y avait pas de photos et pas de vidéos.
[01:45:50.000] Il n'y avait pas de caméra USB.
[01:45:53.000] Capturer des images dans les ordinateurs, c'était vraiment compliqué.
[01:45:56.000] Il fallait acheter des gros trucs très chers.
[01:46:00.000] Mais bon, il y avait des projets un peu comme ça parce que ça intéressait la Poste, d'automatiser le tri des codes postaux.
[01:46:10.000] Et puis, ça intéressait les banques de reconnaître les chiffres sur les chèques, etc.
[01:46:15.000] Donc finalement, il y avait un petit peu de données.
[01:46:17.000] Et on s'est attaché à essayer de voir la performance de ces systèmes, mesurer la performance de ces systèmes pour ce genre de tâches de reconnaissance de chiffres.
[01:46:24.000] Et ça a marché extrêmement bien.
[01:46:27.000] Et donc, c'était un petit pas.
[01:46:29.000] Et puis là, immédiatement, AT&T, l'entreprise qui chapeautait Bell Labs, on a créé un projet pour commercialiser ça, donc faire un système de lecture de chèques, de lecture de formulaire d'inscription.
[01:46:40.000] Il n'y avait pas Internet.
[01:46:41.000] On parle de 1989-1990.
[01:46:44.000] Il y a eu des applications à court terme qui ont eu un impact, mais le but n'était pas de faire de la reconnaissance de caractère.
[01:46:50.000] Le but, c'était de construire des machines intelligentes.
[01:46:53.000] Et puis, on a développé ça.
[01:46:56.000] Puis finalement, l'intérêt de la communauté pour ça a un petit peu diminué dans les années 90.
[01:47:00.000] J'ai fait autre chose entre 1996 et 2002.
[01:47:03.000] Je me suis remis à peu près en 2002.
[01:47:06.000] Et puis là, avec Geoff Hinton et Yoshua Bengio, on s'est dit, il faut absolument ravivier l'intérêt de la communauté pour ces méthodes, parce qu'on sait qu'elles marchent.
[01:47:15.000] Et les raisons pour lesquelles la communauté pense qu'elles ne marchent pas, en fait, sont fausses.
[01:47:19.000] Donc, on s'est attaché à l'idée de montrer qu'elles marchaient, et puis de trouver de nouvelles méthodes.
[01:47:24.000] Et c'est ça qui a causé la réapparition des réseaux neurones et du deep learning.
[01:47:30.000] Et en partie, grâce à la disponibilité d'ordinateurs beaucoup plus puissants qu'on avait à l'époque, et puis de bases de données...
[01:47:39.000] d'images, de photos, de textes.
[01:47:42.000] Grâce à l'Internet, qui n'existait pas dans les années 90, bien sûr.
[01:47:46.000] Et grâce aux réseaux sociaux ensuite.
[01:47:47.000] Et grâce aux réseaux sociaux ensuite.
[01:47:49.000] Je crois qu'il est temps que je te laisse filer.
[01:47:53.000] Merci Yann, tu sais, c'est pour ce genre d'échange que je fais ce podcast, parce que j'ai envie de comprendre où est-ce qu'on est, où est-ce qu'on en est, sans jugement sur est-ce que c'est bien, est-ce que c'est pas bien.
[01:48:10.000] Là aujourd'hui, j'ai quand même vraiment l'impression de comprendre plus de choses, beaucoup plus de choses.
[01:48:16.000] Donc je te remercie, j'espère que comme l'Exprimant, j'aurai l'occasion d'en avoir plus de Yann Lequin, peut-être une ou deux fois plus tard.
[01:48:23.000] On viendra à New York s'il le faut.
[01:48:25.000] En tout cas, je serai ravi.
[01:48:27.000] Et puis, écoute, je suis impatient de voir la suite, et puis de pouvoir tester un peu toutes ces applications que je n'ai pas encore testées chez Meta, en tout cas.
[01:48:37.000] D'accord.
[01:48:38.000] Et puis, peut-être si on fait effectivement des progrès, tels que je les ai décrits dans l'année qui vient, on pourra avoir une autre session.
[01:48:45.000] J'espère que ça va être utile à tes auditeurs.
[01:48:48.000] Je suis sûr que ça sera utile.
[01:48:49.000] Je pense que ça créera des vocations aussi chez des devs et chez des personnes.
[01:48:53.000] Et puis, ça va permettre de comprendre, je pense, beaucoup de choses, parce que beaucoup de personnes ne parlent pas l'anglais.
[01:48:59.000] Je pense que l'audio est un moment important dans ces compréhensions.
[01:49:03.000] Tu vois, d'avoir la durée qu'on a eue, c'est vraiment quelque chose de très important.
[01:49:08.000] Donc, merci beaucoup.
[01:49:10.000] On te suit sur LinkedIn ou est-ce que tu publies un peu ?
[01:49:12.000] Je publie un peu partout sur LinkedIn.
[01:49:15.000] Sur Insta peut-être ?
[01:49:16.000] Alors, pas beaucoup sur Insta, plutôt sur Threads.
[01:49:18.000] OK.
[01:49:19.000] Mais j'aime bien le texte.
[01:49:22.000] Insta, c'est un peu trop centré sur la photo.
[01:49:26.000] Donc, sur Threads, enfin Instagram Threads, sur X, sur LinkedIn et sur Facebook.
[01:49:34.000] Et sur Facebook, en fait, les discussions sont plus intellectuelles que sur les autres plateformes.
[01:49:39.000] Intéressant.
[01:49:40.000] X Twitter, c'est plus news rapide et puis des gens qui s'entretuent.
[01:49:48.000] Mais Facebook, c'est plus intellectuel.
[01:49:52.000] Et puis, LinkedIn, c'est un peu plus professionnel.
[01:49:55.000] Mais j'ai beaucoup de...
[01:49:58.000] Sur X et LinkedIn, je crois que j'ai 700 000 followers sur chacune des deux.
[01:50:04.000] Et puis, Threads, c'est une nouvelle plateforme.
[01:50:07.000] C'est un peu intéressant.
[01:50:08.000] Intéressant.
[01:50:09.000] Je n'y suis pas assez, en effet.
[01:50:10.000] Mais tu ne vas peut-être pas quand même réussir à me faire revenir sur Facebook.
[01:50:13.000] On ne sait pas.
[01:50:14.000] Peut-être.
[01:50:15.000] Si tu me dis que c'est plus intellectuel.
[01:50:16.000] C'est plus intellectuel, il n'y a pas de doute.
[01:50:18.000] Mais c'est possible.
[01:50:20.000] En fait, j'y suis toujours.
[01:50:21.000] Mais j'y vais assez peu parce que j'ai peu d'usage.
[01:50:23.000] Merci, Yann.
[01:50:24.000] Le cas, on te suit partout.
[01:50:26.000] Merci aussi à Violenne Gressier qui nous a aidé à faire ça.
[01:50:31.000] Merci, Anne-Sophie, de nous avoir permis de faire tout ça aussi.
[01:50:34.000] Et puis, à Julien Codorniou, qu'on embrasse, qui est tellement important pour Générations du Durcelle, qui nous aide à avoir beaucoup d'invités, qui écoutent et qui fait ses retours, qui m'aident à progresser.
[01:50:46.000] Donc, on t'embrasse, Julien.
[01:50:48.000] Aussi, Violenne, tout le monde.
[01:50:49.000] Merci, Yann.
[01:50:50.000] A plus.
[01:50:51.000] Et si vous êtes nouveau sur Générations du Durcelle, je vous le demande à chaque fois.
[01:50:53.000] Mais il y en a plein qui ne l'ont pas fait.
[01:50:55.000] Appuyez sur follow, appuyez sur like et partagez cet épisode à deux personnes qui seront intéressées.
[01:51:01.000] J'espère qu'il est assez compréhensible pour tout le monde.
[01:51:03.000] En tout cas, il a été pour moi.
[01:51:05.000] Et comme j'ai bossé, contrairement à ce que j'ai dit, avec beaucoup de personnes, je crois que je ne bosse qu'avec des gens plus intelligents que moi.
[01:51:09.000] Je me pose des questions, d'ailleurs.
[01:51:11.000] Eh bien, vous devriez le comprendre aussi.
[01:51:14.000] A plus.
[01:51:15.000] Salut.
[01:51:16.000] Merci beaucoup.
[01:51:23.000] Sous-titrage ST' 501

